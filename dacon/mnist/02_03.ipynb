{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ooCpvRmT-MkR"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import Conv2D,MaxPooling2D,BatchNormalization,Flatten,Dropout,Input,Activation,Dense,GlobalAveragePooling2D,Add,ZeroPadding2D,AveragePooling2D\n",
    "from tensorflow.keras.models import Sequential,Model,load_model\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tensorflow.keras.callbacks import EarlyStopping,ModelCheckpoint,ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GysUTZTp-MkX"
   },
   "source": [
    "# 모델링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensembles(index):\n",
    "    result = []\n",
    "    for i in range(1,index+1):\n",
    "        a = pd.read_csv(\"./AI_models/loss_kfold_{}.csv\".format(i),index_col=0)\n",
    "        b = pd.read_csv(\"./AI_models/accuracy_kfold_{}.csv\".format(i),index_col=0)\n",
    "        result.append(a.values)\n",
    "        result.append(b.values)\n",
    "    result = np.concatenate(result,axis=1)\n",
    "    ### 합쳐놓음\n",
    "    \n",
    "    mode_list=[]\n",
    "    for j in range(len(result)):\n",
    "        count_list=[0,0,0,0,0,0,0,0,0,0]\n",
    "        k = list(result[j])\n",
    "        for n in k:\n",
    "            count_list[n]+=1\n",
    "        mode = count_list.index(max(count_list))\n",
    "        mode_list.append(mode)\n",
    "    return np.array(mode_list).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "s4kX312e-MkY"
   },
   "outputs": [],
   "source": [
    "def modeling():\n",
    "    inputs = Input(shape=(28,28,1))\n",
    "    x = inputs\n",
    "    _x = Conv2D(64,3,padding='same')(x)\n",
    "    _x = BatchNormalization()(_x)\n",
    "    _x = Activation('relu')(_x)\n",
    "    _x = Conv2D(512,3,padding='same')(_x)\n",
    "    _x = BatchNormalization()(_x)\n",
    "    _x = Activation('relu')(_x)\n",
    "    _x = Conv2D(256,3,padding='same')(_x)\n",
    "    _x = BatchNormalization()(_x)\n",
    "    _x = Activation('relu')(_x)\n",
    "    x = _x\n",
    "    _x = Conv2D(256,3,padding='same')(x)\n",
    "    _x = BatchNormalization()(_x)\n",
    "    _x = Activation('relu')(_x)\n",
    "    _x = Conv2D(128,3,padding='same')(_x)\n",
    "    _x = BatchNormalization()(_x)\n",
    "    _x = Activation('relu')(_x)\n",
    "    _x = Conv2D(256,3,padding='same')(_x)\n",
    "    _x = BatchNormalization()(_x)\n",
    "    _x = Activation('relu')(_x)\n",
    "    _x = Conv2D(512,3,padding='same')(_x)\n",
    "    _x = BatchNormalization()(_x)\n",
    "    _x = Activation('relu')(_x)\n",
    "    _x = Conv2D(1024,3,padding='same')(_x)\n",
    "    _x = BatchNormalization()(_x)\n",
    "    _x = Activation('relu')(_x)\n",
    "    _x = Conv2D(256,3,padding='same')(_x)\n",
    "    _x = BatchNormalization()(_x)\n",
    "    _x = Activation('relu')(_x)\n",
    "    x = x+_x\n",
    "    x = MaxPooling2D(2)(x)\n",
    "    _x = Conv2D(256,3,padding='same')(x)\n",
    "    _x = BatchNormalization()(_x)\n",
    "    _x = Activation('relu')(_x)\n",
    "    _x = Conv2D(128,3,padding='same')(_x)\n",
    "    _x = BatchNormalization()(_x)\n",
    "    _x = Activation('relu')(_x)\n",
    "    _x = Conv2D(256,3,padding='same')(x)\n",
    "    _x = BatchNormalization()(_x)\n",
    "    _x = Activation('relu')(_x)\n",
    "    _x = Conv2D(512,3,padding='same')(_x)\n",
    "    _x = BatchNormalization()(_x)\n",
    "    _x = Activation('relu')(_x)\n",
    "    _x = Conv2D(1024,3,padding='same')(_x)\n",
    "    _x = BatchNormalization()(_x)\n",
    "    _x = Activation('relu')(_x)\n",
    "    _x = Conv2D(256,3,padding='same')(_x)\n",
    "    _x = BatchNormalization()(_x)\n",
    "    _x = Activation('relu')(_x)\n",
    "    x = x+_x\n",
    "    x = MaxPooling2D(2)(x)\n",
    "    _x = Conv2D(256,3,padding='same')(x)\n",
    "    _x = BatchNormalization()(_x)\n",
    "    _x = Activation('relu')(_x)\n",
    "    _x = Conv2D(128,3,padding='same')(_x)\n",
    "    _x = BatchNormalization()(_x)\n",
    "    _x = Activation('relu')(_x)\n",
    "    _x = Conv2D(256,3,padding='same')(x)\n",
    "    _x = BatchNormalization()(_x)\n",
    "    _x = Activation('relu')(_x)\n",
    "    _x = Conv2D(512,3,padding='same')(_x)\n",
    "    _x = BatchNormalization()(_x)\n",
    "    _x = Activation('relu')(_x)\n",
    "    _x = Conv2D(1024,3,padding='same')(_x)\n",
    "    _x = BatchNormalization()(_x)\n",
    "    _x = Activation('relu')(_x)\n",
    "    _x = Conv2D(256,3,padding='same')(_x)\n",
    "    _x = BatchNormalization()(_x)\n",
    "    _x = Activation('relu')(_x)\n",
    "    x = x+_x\n",
    "    x = MaxPooling2D(2)(x)\n",
    "    _x = Conv2D(256,3,padding='same')(x)\n",
    "    _x = BatchNormalization()(_x)\n",
    "    _x = Activation('relu')(_x)\n",
    "    _x = Conv2D(256,3,padding='same')(_x)\n",
    "    _x = BatchNormalization()(_x)\n",
    "    _x = Activation('relu')(_x)\n",
    "    _x = Conv2D(256,3,padding='same')(_x)\n",
    "    _x = BatchNormalization()(_x)\n",
    "    _x = Activation('relu')(_x)\n",
    "    x = x+_x\n",
    "    x = MaxPooling2D(2)(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(1024)(x)\n",
    "    x = Dense(10,activation='softmax')(x)\n",
    "    outputs=x\n",
    "    model = Model(inputs=inputs,outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cccyJfWO-MkY"
   },
   "source": [
    "# 하이퍼 파라미터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "W73nGvZM-MkZ"
   },
   "outputs": [],
   "source": [
    "epochs = 2000\n",
    "es = EarlyStopping(monitor='val_loss',patience=100)\n",
    "reLR = ReduceLROnPlateau(patience=40,verbose=1,factor=0.5)\n",
    "kfold = StratifiedKFold(n_splits=10,shuffle=True)\n",
    "datagen = ImageDataGenerator(height_shift_range=(-1,1),width_shift_range=(-1,1))\n",
    "datagen2 = ImageDataGenerator()\n",
    "optimizer = Adam(lr=0.002,epsilon=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oWqLv-B1-MkZ"
   },
   "source": [
    "# 데이터 불러오기 및 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "j6UbQKZk-MkZ",
    "outputId": "26984b86-65c4-4adf-c0dc-bcb09f17d346"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2048, 28, 28, 1) (2048,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 9, 0, 5])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"train.csv\",index_col=[0])\n",
    "y = df.values[:,0].astype('int32')\n",
    "x = df.values[:,2:].astype('float32')/255.0\n",
    "# print(x.shape,y.shape)               # (2048, 28, 28) (2048,)\n",
    "#onehot = OneHotEncoder()\n",
    "#y = onehot.fit_transform(y.reshape(-1,1)).toarray().astype('float32')\n",
    "x = x.reshape(-1,28,28,1)\n",
    "# x_train,x_val,y_train,y_val = train_test_split(x,y,test_size=0.15)\n",
    "# x_train = x_train.reshape(-1,28,28,1)#[:,2:26,2:26,:]\n",
    "# x_val = x_val.reshape(-1,28,28,1)#[:,2:26,2:26,:]\n",
    "# print(x_train.shape,x_val.shape,y_train.shape,y_val.shape)\n",
    "print(x.shape,y.shape) \n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LmMESLTT-Mkb",
    "outputId": "6e97efa1-d705-4b3d-9e71-4261745da5bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      " 2/58 [>.............................] - ETA: 7s - loss: 34.6502 - accuracy: 0.1094WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0999s vs `on_train_batch_end` time: 0.1905s). Check your callbacks.\n",
      "58/58 [==============================] - ETA: 0s - loss: 14.8093 - accuracy: 0.1036\n",
      "Epoch 00001: val_loss improved from inf to 88138.52344, saving model to ./home_models_0205\\02_04_AI_val_loss_index_1.h5\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.10244, saving model to ./home_models_0205\\02_04_AI_val_accuracy_index_1.h5\n",
      "58/58 [==============================] - 22s 386ms/step - loss: 14.8093 - accuracy: 0.1036 - val_loss: 88138.5234 - val_accuracy: 0.1024\n",
      "Epoch 2/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 2.4471 - accuracy: 0.1118\n",
      "Epoch 00002: val_loss improved from 88138.52344 to 612.89612, saving model to ./home_models_0205\\02_04_AI_val_loss_index_1.h5\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.10244 to 0.10732, saving model to ./home_models_0205\\02_04_AI_val_accuracy_index_1.h5\n",
      "58/58 [==============================] - 22s 373ms/step - loss: 2.4471 - accuracy: 0.1118 - val_loss: 612.8961 - val_accuracy: 0.1073\n",
      "Epoch 3/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 2.4324 - accuracy: 0.1248\n",
      "Epoch 00003: val_loss improved from 612.89612 to 259.94006, saving model to ./home_models_0205\\02_04_AI_val_loss_index_1.h5\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.10732 to 0.11220, saving model to ./home_models_0205\\02_04_AI_val_accuracy_index_1.h5\n",
      "58/58 [==============================] - 21s 363ms/step - loss: 2.4324 - accuracy: 0.1248 - val_loss: 259.9401 - val_accuracy: 0.1122\n",
      "Epoch 4/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 2.2424 - accuracy: 0.1953\n",
      "Epoch 00004: val_loss improved from 259.94006 to 159.38536, saving model to ./home_models_0205\\02_04_AI_val_loss_index_1.h5\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.11220\n",
      "58/58 [==============================] - 19s 330ms/step - loss: 2.2424 - accuracy: 0.1953 - val_loss: 159.3854 - val_accuracy: 0.1073\n",
      "Epoch 5/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 2.2466 - accuracy: 0.2360\n",
      "Epoch 00005: val_loss improved from 159.38536 to 112.20219, saving model to ./home_models_0205\\02_04_AI_val_loss_index_1.h5\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.11220 to 0.13171, saving model to ./home_models_0205\\02_04_AI_val_accuracy_index_1.h5\n",
      "58/58 [==============================] - 21s 366ms/step - loss: 2.2466 - accuracy: 0.2360 - val_loss: 112.2022 - val_accuracy: 0.1317\n",
      "Epoch 6/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 2.0875 - accuracy: 0.2729\n",
      "Epoch 00006: val_loss improved from 112.20219 to 4.97276, saving model to ./home_models_0205\\02_04_AI_val_loss_index_1.h5\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.13171\n",
      "58/58 [==============================] - 19s 326ms/step - loss: 2.0875 - accuracy: 0.2729 - val_loss: 4.9728 - val_accuracy: 0.1073\n",
      "Epoch 7/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 1.7857 - accuracy: 0.3700\n",
      "Epoch 00007: val_loss improved from 4.97276 to 3.36770, saving model to ./home_models_0205\\02_04_AI_val_loss_index_1.h5\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.13171\n",
      "58/58 [==============================] - 19s 331ms/step - loss: 1.7857 - accuracy: 0.3700 - val_loss: 3.3677 - val_accuracy: 0.1317\n",
      "Epoch 8/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 1.7118 - accuracy: 0.3977\n",
      "Epoch 00008: val_loss did not improve from 3.36770\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.13171\n",
      "58/58 [==============================] - 17s 294ms/step - loss: 1.7118 - accuracy: 0.3977 - val_loss: 4.1461 - val_accuracy: 0.1317\n",
      "Epoch 9/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 1.5942 - accuracy: 0.4563\n",
      "Epoch 00009: val_loss did not improve from 3.36770\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.13171 to 0.16585, saving model to ./home_models_0205\\02_04_AI_val_accuracy_index_1.h5\n",
      "58/58 [==============================] - 32s 547ms/step - loss: 1.5942 - accuracy: 0.4563 - val_loss: 4.6631 - val_accuracy: 0.1659\n",
      "Epoch 10/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 1.4644 - accuracy: 0.4905\n",
      "Epoch 00010: val_loss improved from 3.36770 to 2.24873, saving model to ./home_models_0205\\02_04_AI_val_loss_index_1.h5\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.16585 to 0.29756, saving model to ./home_models_0205\\02_04_AI_val_accuracy_index_1.h5\n",
      "58/58 [==============================] - 48s 828ms/step - loss: 1.4644 - accuracy: 0.4905 - val_loss: 2.2487 - val_accuracy: 0.2976\n",
      "Epoch 11/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 1.1708 - accuracy: 0.5855\n",
      "Epoch 00011: val_loss did not improve from 2.24873\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.29756\n",
      "58/58 [==============================] - 17s 294ms/step - loss: 1.1708 - accuracy: 0.5855 - val_loss: 2.9657 - val_accuracy: 0.2683\n",
      "Epoch 12/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 1.0549 - accuracy: 0.6403\n",
      "Epoch 00012: val_loss improved from 2.24873 to 1.65478, saving model to ./home_models_0205\\02_04_AI_val_loss_index_1.h5\n",
      "\n",
      "Epoch 00012: val_accuracy improved from 0.29756 to 0.45854, saving model to ./home_models_0205\\02_04_AI_val_accuracy_index_1.h5\n",
      "58/58 [==============================] - 48s 822ms/step - loss: 1.0549 - accuracy: 0.6403 - val_loss: 1.6548 - val_accuracy: 0.4585\n",
      "Epoch 13/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.9477 - accuracy: 0.6663\n",
      "Epoch 00013: val_loss improved from 1.65478 to 1.50674, saving model to ./home_models_0205\\02_04_AI_val_loss_index_1.h5\n",
      "\n",
      "Epoch 00013: val_accuracy improved from 0.45854 to 0.52683, saving model to ./home_models_0205\\02_04_AI_val_accuracy_index_1.h5\n",
      "58/58 [==============================] - 47s 815ms/step - loss: 0.9477 - accuracy: 0.6663 - val_loss: 1.5067 - val_accuracy: 0.5268\n",
      "Epoch 14/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.9874 - accuracy: 0.6620\n",
      "Epoch 00014: val_loss did not improve from 1.50674\n",
      "\n",
      "Epoch 00014: val_accuracy improved from 0.52683 to 0.61463, saving model to ./home_models_0205\\02_04_AI_val_accuracy_index_1.h5\n",
      "58/58 [==============================] - 18s 319ms/step - loss: 0.9874 - accuracy: 0.6620 - val_loss: 1.5767 - val_accuracy: 0.6146\n",
      "Epoch 15/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.9045 - accuracy: 0.6989\n",
      "Epoch 00015: val_loss did not improve from 1.50674\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.61463\n",
      "58/58 [==============================] - 17s 294ms/step - loss: 0.9045 - accuracy: 0.6989 - val_loss: 2.1006 - val_accuracy: 0.4732\n",
      "Epoch 16/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.7067 - accuracy: 0.7537\n",
      "Epoch 00016: val_loss improved from 1.50674 to 0.94767, saving model to ./home_models_0205\\02_04_AI_val_loss_index_1.h5\n",
      "\n",
      "Epoch 00016: val_accuracy improved from 0.61463 to 0.74146, saving model to ./home_models_0205\\02_04_AI_val_accuracy_index_1.h5\n",
      "58/58 [==============================] - 47s 817ms/step - loss: 0.7067 - accuracy: 0.7537 - val_loss: 0.9477 - val_accuracy: 0.7415\n",
      "Epoch 17/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.6284 - accuracy: 0.7927\n",
      "Epoch 00017: val_loss did not improve from 0.94767\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.74146\n",
      "58/58 [==============================] - 17s 293ms/step - loss: 0.6284 - accuracy: 0.7927 - val_loss: 4.4799 - val_accuracy: 0.2244\n",
      "Epoch 18/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.5812 - accuracy: 0.7933\n",
      "Epoch 00018: val_loss did not improve from 0.94767\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.74146\n",
      "58/58 [==============================] - 17s 294ms/step - loss: 0.5812 - accuracy: 0.7933 - val_loss: 1.3665 - val_accuracy: 0.5756\n",
      "Epoch 19/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.4407 - accuracy: 0.8535\n",
      "Epoch 00019: val_loss improved from 0.94767 to 0.89917, saving model to ./home_models_0205\\02_04_AI_val_loss_index_1.h5\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.74146\n",
      "58/58 [==============================] - 33s 566ms/step - loss: 0.4407 - accuracy: 0.8535 - val_loss: 0.8992 - val_accuracy: 0.7171\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.4942 - accuracy: 0.8345\n",
      "Epoch 00020: val_loss did not improve from 0.89917\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.74146\n",
      "58/58 [==============================] - 17s 294ms/step - loss: 0.4942 - accuracy: 0.8345 - val_loss: 0.9135 - val_accuracy: 0.7220\n",
      "Epoch 21/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.4490 - accuracy: 0.8486\n",
      "Epoch 00021: val_loss improved from 0.89917 to 0.87166, saving model to ./home_models_0205\\02_04_AI_val_loss_index_1.h5\n",
      "\n",
      "Epoch 00021: val_accuracy improved from 0.74146 to 0.76098, saving model to ./home_models_0205\\02_04_AI_val_accuracy_index_1.h5\n",
      "58/58 [==============================] - 49s 847ms/step - loss: 0.4490 - accuracy: 0.8486 - val_loss: 0.8717 - val_accuracy: 0.7610\n",
      "Epoch 22/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.3882 - accuracy: 0.8687\n",
      "Epoch 00022: val_loss did not improve from 0.87166\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.76098\n",
      "58/58 [==============================] - 17s 294ms/step - loss: 0.3882 - accuracy: 0.8687 - val_loss: 1.2405 - val_accuracy: 0.7024\n",
      "Epoch 23/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.2946 - accuracy: 0.8991\n",
      "Epoch 00023: val_loss did not improve from 0.87166\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.76098\n",
      "58/58 [==============================] - 17s 294ms/step - loss: 0.2946 - accuracy: 0.8991 - val_loss: 1.2978 - val_accuracy: 0.6634\n",
      "Epoch 24/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.3330 - accuracy: 0.8871\n",
      "Epoch 00024: val_loss did not improve from 0.87166\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.76098\n",
      "58/58 [==============================] - 17s 294ms/step - loss: 0.3330 - accuracy: 0.8871 - val_loss: 0.9365 - val_accuracy: 0.7366\n",
      "Epoch 25/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.3574 - accuracy: 0.8757\n",
      "Epoch 00025: val_loss improved from 0.87166 to 0.78052, saving model to ./home_models_0205\\02_04_AI_val_loss_index_1.h5\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.76098\n",
      "58/58 [==============================] - 33s 570ms/step - loss: 0.3574 - accuracy: 0.8757 - val_loss: 0.7805 - val_accuracy: 0.7610\n",
      "Epoch 26/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.2419 - accuracy: 0.9224\n",
      "Epoch 00026: val_loss improved from 0.78052 to 0.72440, saving model to ./home_models_0205\\02_04_AI_val_loss_index_1.h5\n",
      "\n",
      "Epoch 00026: val_accuracy improved from 0.76098 to 0.79024, saving model to ./home_models_0205\\02_04_AI_val_accuracy_index_1.h5\n",
      "58/58 [==============================] - 35s 600ms/step - loss: 0.2419 - accuracy: 0.9224 - val_loss: 0.7244 - val_accuracy: 0.7902\n",
      "Epoch 27/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.2210 - accuracy: 0.9230\n",
      "Epoch 00027: val_loss did not improve from 0.72440\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.79024\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 0.2210 - accuracy: 0.9230 - val_loss: 1.1245 - val_accuracy: 0.7561\n",
      "Epoch 28/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.2685 - accuracy: 0.9105\n",
      "Epoch 00028: val_loss did not improve from 0.72440\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.79024\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 0.2685 - accuracy: 0.9105 - val_loss: 1.1154 - val_accuracy: 0.7171\n",
      "Epoch 29/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.2915 - accuracy: 0.9072\n",
      "Epoch 00029: val_loss did not improve from 0.72440\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.79024\n",
      "58/58 [==============================] - 17s 294ms/step - loss: 0.2915 - accuracy: 0.9072 - val_loss: 1.5107 - val_accuracy: 0.6829\n",
      "Epoch 30/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.3387 - accuracy: 0.8931\n",
      "Epoch 00030: val_loss did not improve from 0.72440\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.79024\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 0.3387 - accuracy: 0.8931 - val_loss: 1.1569 - val_accuracy: 0.7220\n",
      "Epoch 31/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.2139 - accuracy: 0.9284\n",
      "Epoch 00031: val_loss did not improve from 0.72440\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.79024\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 0.2139 - accuracy: 0.9284 - val_loss: 0.8048 - val_accuracy: 0.7902\n",
      "Epoch 32/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.2115 - accuracy: 0.9300\n",
      "Epoch 00032: val_loss did not improve from 0.72440\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.79024\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 0.2115 - accuracy: 0.9300 - val_loss: 1.5443 - val_accuracy: 0.6244\n",
      "Epoch 33/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1867 - accuracy: 0.9349\n",
      "Epoch 00033: val_loss did not improve from 0.72440\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.79024\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 0.1867 - accuracy: 0.9349 - val_loss: 1.2830 - val_accuracy: 0.7171\n",
      "Epoch 34/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1665 - accuracy: 0.9457\n",
      "Epoch 00034: val_loss did not improve from 0.72440\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.79024\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 0.1665 - accuracy: 0.9457 - val_loss: 1.1985 - val_accuracy: 0.7220\n",
      "Epoch 35/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1302 - accuracy: 0.9620\n",
      "Epoch 00035: val_loss did not improve from 0.72440\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.79024\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 0.1302 - accuracy: 0.9620 - val_loss: 1.5429 - val_accuracy: 0.7073\n",
      "Epoch 36/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.2551 - accuracy: 0.9192\n",
      "Epoch 00036: val_loss did not improve from 0.72440\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.79024\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 0.2551 - accuracy: 0.9192 - val_loss: 1.6033 - val_accuracy: 0.6195\n",
      "Epoch 37/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1044 - accuracy: 0.9653\n",
      "Epoch 00037: val_loss did not improve from 0.72440\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.79024\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 0.1044 - accuracy: 0.9653 - val_loss: 0.9399 - val_accuracy: 0.7756\n",
      "Epoch 38/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1111 - accuracy: 0.9664\n",
      "Epoch 00038: val_loss improved from 0.72440 to 0.69660, saving model to ./home_models_0205\\02_04_AI_val_loss_index_1.h5\n",
      "\n",
      "Epoch 00038: val_accuracy improved from 0.79024 to 0.80976, saving model to ./home_models_0205\\02_04_AI_val_accuracy_index_1.h5\n",
      "58/58 [==============================] - 48s 825ms/step - loss: 0.1111 - accuracy: 0.9664 - val_loss: 0.6966 - val_accuracy: 0.8098\n",
      "Epoch 39/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1211 - accuracy: 0.9598\n",
      "Epoch 00039: val_loss did not improve from 0.69660\n",
      "\n",
      "Epoch 00039: val_accuracy improved from 0.80976 to 0.81463, saving model to ./home_models_0205\\02_04_AI_val_accuracy_index_1.h5\n",
      "58/58 [==============================] - 19s 320ms/step - loss: 0.1211 - accuracy: 0.9598 - val_loss: 0.8437 - val_accuracy: 0.8146\n",
      "Epoch 40/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1024 - accuracy: 0.9653\n",
      "Epoch 00040: val_loss did not improve from 0.69660\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.81463\n",
      "58/58 [==============================] - 17s 294ms/step - loss: 0.1024 - accuracy: 0.9653 - val_loss: 0.9353 - val_accuracy: 0.8098\n",
      "Epoch 41/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1376 - accuracy: 0.9501\n",
      "Epoch 00041: val_loss did not improve from 0.69660\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.81463\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 0.1376 - accuracy: 0.9501 - val_loss: 1.2671 - val_accuracy: 0.7610\n",
      "Epoch 42/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1205 - accuracy: 0.9609\n",
      "Epoch 00042: val_loss did not improve from 0.69660\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.81463\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 0.1205 - accuracy: 0.9609 - val_loss: 0.9324 - val_accuracy: 0.8146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1321 - accuracy: 0.9555\n",
      "Epoch 00043: val_loss did not improve from 0.69660\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.81463\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 0.1321 - accuracy: 0.9555 - val_loss: 1.1534 - val_accuracy: 0.8146\n",
      "Epoch 44/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1544 - accuracy: 0.9555\n",
      "Epoch 00044: val_loss did not improve from 0.69660\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.81463\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 0.1544 - accuracy: 0.9555 - val_loss: 1.2363 - val_accuracy: 0.7756\n",
      "Epoch 45/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.2380 - accuracy: 0.9343\n",
      "Epoch 00045: val_loss did not improve from 0.69660\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.81463\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 0.2380 - accuracy: 0.9343 - val_loss: 1.4664 - val_accuracy: 0.7366\n",
      "Epoch 46/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1634 - accuracy: 0.9474\n",
      "Epoch 00046: val_loss did not improve from 0.69660\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.81463\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 0.1634 - accuracy: 0.9474 - val_loss: 1.5096 - val_accuracy: 0.7659\n",
      "Epoch 47/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1661 - accuracy: 0.9474\n",
      "Epoch 00047: val_loss did not improve from 0.69660\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.81463\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 0.1661 - accuracy: 0.9474 - val_loss: 0.9401 - val_accuracy: 0.8049\n",
      "Epoch 48/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1450 - accuracy: 0.9501\n",
      "Epoch 00048: val_loss did not improve from 0.69660\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.81463\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 0.1450 - accuracy: 0.9501 - val_loss: 1.1032 - val_accuracy: 0.7902\n",
      "Epoch 49/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.2085 - accuracy: 0.9409\n",
      "Epoch 00049: val_loss did not improve from 0.69660\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.81463\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 0.2085 - accuracy: 0.9409 - val_loss: 2.3164 - val_accuracy: 0.6244\n",
      "Epoch 50/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.2189 - accuracy: 0.9360\n",
      "Epoch 00050: val_loss did not improve from 0.69660\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.81463\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 0.2189 - accuracy: 0.9360 - val_loss: 1.1593 - val_accuracy: 0.7756\n",
      "Epoch 51/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1911 - accuracy: 0.9430\n",
      "Epoch 00051: val_loss did not improve from 0.69660\n",
      "\n",
      "Epoch 00051: val_accuracy improved from 0.81463 to 0.82927, saving model to ./home_models_0205\\02_04_AI_val_accuracy_index_1.h5\n",
      "58/58 [==============================] - 32s 556ms/step - loss: 0.1911 - accuracy: 0.9430 - val_loss: 0.7477 - val_accuracy: 0.8293\n",
      "Epoch 52/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1102 - accuracy: 0.9658\n",
      "Epoch 00052: val_loss did not improve from 0.69660\n",
      "\n",
      "Epoch 00052: val_accuracy improved from 0.82927 to 0.83902, saving model to ./home_models_0205\\02_04_AI_val_accuracy_index_1.h5\n",
      "58/58 [==============================] - 19s 332ms/step - loss: 0.1102 - accuracy: 0.9658 - val_loss: 0.7362 - val_accuracy: 0.8390\n",
      "Epoch 53/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.2002 - accuracy: 0.9387\n",
      "Epoch 00053: val_loss did not improve from 0.69660\n",
      "\n",
      "Epoch 00053: val_accuracy did not improve from 0.83902\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 0.2002 - accuracy: 0.9387 - val_loss: 1.2107 - val_accuracy: 0.7902\n",
      "Epoch 54/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1572 - accuracy: 0.9495\n",
      "Epoch 00054: val_loss did not improve from 0.69660\n",
      "\n",
      "Epoch 00054: val_accuracy did not improve from 0.83902\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 0.1572 - accuracy: 0.9495 - val_loss: 1.0338 - val_accuracy: 0.7902\n",
      "Epoch 55/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0827 - accuracy: 0.9734\n",
      "Epoch 00055: val_loss did not improve from 0.69660\n",
      "\n",
      "Epoch 00055: val_accuracy improved from 0.83902 to 0.85366, saving model to ./home_models_0205\\02_04_AI_val_accuracy_index_1.h5\n",
      "58/58 [==============================] - 32s 552ms/step - loss: 0.0827 - accuracy: 0.9734 - val_loss: 0.7779 - val_accuracy: 0.8537\n",
      "Epoch 56/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1228 - accuracy: 0.9658\n",
      "Epoch 00056: val_loss did not improve from 0.69660\n",
      "\n",
      "Epoch 00056: val_accuracy did not improve from 0.85366\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 0.1228 - accuracy: 0.9658 - val_loss: 1.1355 - val_accuracy: 0.8146\n",
      "Epoch 57/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1190 - accuracy: 0.9636\n",
      "Epoch 00057: val_loss did not improve from 0.69660\n",
      "\n",
      "Epoch 00057: val_accuracy did not improve from 0.85366\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 0.1190 - accuracy: 0.9636 - val_loss: 1.0521 - val_accuracy: 0.8146\n",
      "Epoch 58/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1124 - accuracy: 0.9669\n",
      "Epoch 00058: val_loss did not improve from 0.69660\n",
      "\n",
      "Epoch 00058: val_accuracy did not improve from 0.85366\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 0.1124 - accuracy: 0.9669 - val_loss: 0.8994 - val_accuracy: 0.8341\n",
      "Epoch 59/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1680 - accuracy: 0.9528\n",
      "Epoch 00059: val_loss did not improve from 0.69660\n",
      "\n",
      "Epoch 00059: val_accuracy did not improve from 0.85366\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 0.1680 - accuracy: 0.9528 - val_loss: 1.0571 - val_accuracy: 0.7805\n",
      "Epoch 60/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.2229 - accuracy: 0.9333\n",
      "Epoch 00060: val_loss did not improve from 0.69660\n",
      "\n",
      "Epoch 00060: val_accuracy did not improve from 0.85366\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 0.2229 - accuracy: 0.9333 - val_loss: 1.6956 - val_accuracy: 0.7171\n",
      "Epoch 61/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.2019 - accuracy: 0.9381\n",
      "Epoch 00061: val_loss did not improve from 0.69660\n",
      "\n",
      "Epoch 00061: val_accuracy did not improve from 0.85366\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 0.2019 - accuracy: 0.9381 - val_loss: 0.9300 - val_accuracy: 0.8244\n",
      "Epoch 62/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.2094 - accuracy: 0.9436\n",
      "Epoch 00062: val_loss did not improve from 0.69660\n",
      "\n",
      "Epoch 00062: val_accuracy improved from 0.85366 to 0.85854, saving model to ./home_models_0205\\02_04_AI_val_accuracy_index_1.h5\n",
      "58/58 [==============================] - 32s 555ms/step - loss: 0.2094 - accuracy: 0.9436 - val_loss: 0.7909 - val_accuracy: 0.8585\n",
      "Epoch 63/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0896 - accuracy: 0.9685\n",
      "Epoch 00063: val_loss did not improve from 0.69660\n",
      "\n",
      "Epoch 00063: val_accuracy did not improve from 0.85854\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 0.0896 - accuracy: 0.9685 - val_loss: 1.0119 - val_accuracy: 0.8488\n",
      "Epoch 64/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0712 - accuracy: 0.9772\n",
      "Epoch 00064: val_loss did not improve from 0.69660\n",
      "\n",
      "Epoch 00064: val_accuracy did not improve from 0.85854\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 0.0712 - accuracy: 0.9772 - val_loss: 1.4101 - val_accuracy: 0.8000\n",
      "Epoch 65/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1378 - accuracy: 0.9620\n",
      "Epoch 00065: val_loss did not improve from 0.69660\n",
      "\n",
      "Epoch 00065: val_accuracy did not improve from 0.85854\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 0.1378 - accuracy: 0.9620 - val_loss: 0.8652 - val_accuracy: 0.8146\n",
      "Epoch 66/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.2327 - accuracy: 0.9376\n",
      "Epoch 00066: val_loss did not improve from 0.69660\n",
      "\n",
      "Epoch 00066: val_accuracy did not improve from 0.85854\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 0.2327 - accuracy: 0.9376 - val_loss: 1.4083 - val_accuracy: 0.7854\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.3468 - accuracy: 0.9164\n",
      "Epoch 00067: val_loss did not improve from 0.69660\n",
      "\n",
      "Epoch 00067: val_accuracy did not improve from 0.85854\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 0.3468 - accuracy: 0.9164 - val_loss: 1.4466 - val_accuracy: 0.7659\n",
      "Epoch 68/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1952 - accuracy: 0.9506\n",
      "Epoch 00068: val_loss did not improve from 0.69660\n",
      "\n",
      "Epoch 00068: val_accuracy did not improve from 0.85854\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 0.1952 - accuracy: 0.9506 - val_loss: 0.9617 - val_accuracy: 0.8341\n",
      "Epoch 69/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0939 - accuracy: 0.9712\n",
      "Epoch 00069: val_loss did not improve from 0.69660\n",
      "\n",
      "Epoch 00069: val_accuracy did not improve from 0.85854\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 0.0939 - accuracy: 0.9712 - val_loss: 1.0272 - val_accuracy: 0.8244\n",
      "Epoch 70/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0310 - accuracy: 0.9897\n",
      "Epoch 00070: val_loss improved from 0.69660 to 0.60657, saving model to ./home_models_0205\\02_04_AI_val_loss_index_1.h5\n",
      "\n",
      "Epoch 00070: val_accuracy improved from 0.85854 to 0.86341, saving model to ./home_models_0205\\02_04_AI_val_accuracy_index_1.h5\n",
      "58/58 [==============================] - 48s 826ms/step - loss: 0.0310 - accuracy: 0.9897 - val_loss: 0.6066 - val_accuracy: 0.8634\n",
      "Epoch 71/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0224 - accuracy: 0.9908\n",
      "Epoch 00071: val_loss improved from 0.60657 to 0.57753, saving model to ./home_models_0205\\02_04_AI_val_loss_index_1.h5\n",
      "\n",
      "Epoch 00071: val_accuracy did not improve from 0.86341\n",
      "58/58 [==============================] - 32s 557ms/step - loss: 0.0224 - accuracy: 0.9908 - val_loss: 0.5775 - val_accuracy: 0.8634\n",
      "Epoch 72/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0336 - accuracy: 0.9843\n",
      "Epoch 00072: val_loss did not improve from 0.57753\n",
      "\n",
      "Epoch 00072: val_accuracy did not improve from 0.86341\n",
      "58/58 [==============================] - 17s 294ms/step - loss: 0.0336 - accuracy: 0.9843 - val_loss: 1.0906 - val_accuracy: 0.8000\n",
      "Epoch 73/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0309 - accuracy: 0.9902\n",
      "Epoch 00073: val_loss did not improve from 0.57753\n",
      "\n",
      "Epoch 00073: val_accuracy did not improve from 0.86341\n",
      "58/58 [==============================] - 17s 294ms/step - loss: 0.0309 - accuracy: 0.9902 - val_loss: 0.7878 - val_accuracy: 0.8488\n",
      "Epoch 74/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0937 - accuracy: 0.9734\n",
      "Epoch 00074: val_loss did not improve from 0.57753\n",
      "\n",
      "Epoch 00074: val_accuracy did not improve from 0.86341\n",
      "58/58 [==============================] - 17s 294ms/step - loss: 0.0937 - accuracy: 0.9734 - val_loss: 1.2816 - val_accuracy: 0.8000\n",
      "Epoch 75/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.2662 - accuracy: 0.9305\n",
      "Epoch 00075: val_loss did not improve from 0.57753\n",
      "\n",
      "Epoch 00075: val_accuracy did not improve from 0.86341\n",
      "58/58 [==============================] - 17s 294ms/step - loss: 0.2662 - accuracy: 0.9305 - val_loss: 1.2407 - val_accuracy: 0.7951\n",
      "Epoch 76/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1746 - accuracy: 0.9598\n",
      "Epoch 00076: val_loss did not improve from 0.57753\n",
      "\n",
      "Epoch 00076: val_accuracy did not improve from 0.86341\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 0.1746 - accuracy: 0.9598 - val_loss: 1.0991 - val_accuracy: 0.8244\n",
      "Epoch 77/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0699 - accuracy: 0.9772\n",
      "Epoch 00077: val_loss did not improve from 0.57753\n",
      "\n",
      "Epoch 00077: val_accuracy did not improve from 0.86341\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 0.0699 - accuracy: 0.9772 - val_loss: 1.5035 - val_accuracy: 0.7659\n",
      "Epoch 78/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0764 - accuracy: 0.9788\n",
      "Epoch 00078: val_loss did not improve from 0.57753\n",
      "\n",
      "Epoch 00078: val_accuracy did not improve from 0.86341\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 0.0764 - accuracy: 0.9788 - val_loss: 1.0764 - val_accuracy: 0.8488\n",
      "Epoch 79/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0287 - accuracy: 0.9913\n",
      "Epoch 00079: val_loss did not improve from 0.57753\n",
      "\n",
      "Epoch 00079: val_accuracy did not improve from 0.86341\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 0.0287 - accuracy: 0.9913 - val_loss: 0.9458 - val_accuracy: 0.8585\n",
      "Epoch 80/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0360 - accuracy: 0.9913\n",
      "Epoch 00080: val_loss did not improve from 0.57753\n",
      "\n",
      "Epoch 00080: val_accuracy did not improve from 0.86341\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 0.0360 - accuracy: 0.9913 - val_loss: 0.9924 - val_accuracy: 0.8537\n",
      "Epoch 81/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0962 - accuracy: 0.9772\n",
      "Epoch 00081: val_loss did not improve from 0.57753\n",
      "\n",
      "Epoch 00081: val_accuracy did not improve from 0.86341\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 0.0962 - accuracy: 0.9772 - val_loss: 1.3070 - val_accuracy: 0.8293\n",
      "Epoch 82/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1759 - accuracy: 0.9582\n",
      "Epoch 00082: val_loss did not improve from 0.57753\n",
      "\n",
      "Epoch 00082: val_accuracy did not improve from 0.86341\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 0.1759 - accuracy: 0.9582 - val_loss: 1.8327 - val_accuracy: 0.7561\n",
      "Epoch 83/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0695 - accuracy: 0.9788\n",
      "Epoch 00083: val_loss did not improve from 0.57753\n",
      "\n",
      "Epoch 00083: val_accuracy did not improve from 0.86341\n",
      "58/58 [==============================] - 17s 296ms/step - loss: 0.0695 - accuracy: 0.9788 - val_loss: 1.9358 - val_accuracy: 0.7659\n",
      "Epoch 84/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1168 - accuracy: 0.9707\n",
      "Epoch 00084: val_loss did not improve from 0.57753\n",
      "\n",
      "Epoch 00084: val_accuracy did not improve from 0.86341\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 0.1168 - accuracy: 0.9707 - val_loss: 1.2185 - val_accuracy: 0.8146\n",
      "Epoch 85/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0701 - accuracy: 0.9810\n",
      "Epoch 00085: val_loss did not improve from 0.57753\n",
      "\n",
      "Epoch 00085: val_accuracy did not improve from 0.86341\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 0.0701 - accuracy: 0.9810 - val_loss: 0.9703 - val_accuracy: 0.8585\n",
      "Epoch 86/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0290 - accuracy: 0.9908\n",
      "Epoch 00086: val_loss did not improve from 0.57753\n",
      "\n",
      "Epoch 00086: val_accuracy improved from 0.86341 to 0.89268, saving model to ./home_models_0205\\02_04_AI_val_accuracy_index_1.h5\n",
      "58/58 [==============================] - 32s 556ms/step - loss: 0.0290 - accuracy: 0.9908 - val_loss: 0.7500 - val_accuracy: 0.8927\n",
      "Epoch 87/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1096 - accuracy: 0.9729\n",
      "Epoch 00087: val_loss did not improve from 0.57753\n",
      "\n",
      "Epoch 00087: val_accuracy did not improve from 0.89268\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 0.1096 - accuracy: 0.9729 - val_loss: 1.5180 - val_accuracy: 0.8244\n",
      "Epoch 88/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.3497 - accuracy: 0.9354\n",
      "Epoch 00088: val_loss did not improve from 0.57753\n",
      "\n",
      "Epoch 00088: val_accuracy did not improve from 0.89268\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 0.3497 - accuracy: 0.9354 - val_loss: 1.9736 - val_accuracy: 0.6780\n",
      "Epoch 89/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1872 - accuracy: 0.9533\n",
      "Epoch 00089: val_loss did not improve from 0.57753\n",
      "\n",
      "Epoch 00089: val_accuracy did not improve from 0.89268\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 0.1872 - accuracy: 0.9533 - val_loss: 1.0769 - val_accuracy: 0.8341\n",
      "Epoch 90/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1648 - accuracy: 0.9593\n",
      "Epoch 00090: val_loss did not improve from 0.57753\n",
      "\n",
      "Epoch 00090: val_accuracy did not improve from 0.89268\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 0.1648 - accuracy: 0.9593 - val_loss: 2.8252 - val_accuracy: 0.6927\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0971 - accuracy: 0.9788\n",
      "Epoch 00091: val_loss did not improve from 0.57753\n",
      "\n",
      "Epoch 00091: val_accuracy did not improve from 0.89268\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 0.0971 - accuracy: 0.9788 - val_loss: 1.5106 - val_accuracy: 0.8146\n",
      "Epoch 92/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0525 - accuracy: 0.9816\n",
      "Epoch 00092: val_loss did not improve from 0.57753\n",
      "\n",
      "Epoch 00092: val_accuracy did not improve from 0.89268\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 0.0525 - accuracy: 0.9816 - val_loss: 1.1123 - val_accuracy: 0.8439\n",
      "Epoch 93/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0451 - accuracy: 0.9886\n",
      "Epoch 00093: val_loss did not improve from 0.57753\n",
      "\n",
      "Epoch 00093: val_accuracy did not improve from 0.89268\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 0.0451 - accuracy: 0.9886 - val_loss: 1.2928 - val_accuracy: 0.8488\n",
      "Epoch 94/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0440 - accuracy: 0.9897\n",
      "Epoch 00094: val_loss did not improve from 0.57753\n",
      "\n",
      "Epoch 00094: val_accuracy did not improve from 0.89268\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 0.0440 - accuracy: 0.9897 - val_loss: 1.3171 - val_accuracy: 0.8585\n",
      "Epoch 95/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0414 - accuracy: 0.9875\n",
      "Epoch 00095: val_loss did not improve from 0.57753\n",
      "\n",
      "Epoch 00095: val_accuracy did not improve from 0.89268\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 0.0414 - accuracy: 0.9875 - val_loss: 1.2541 - val_accuracy: 0.8244\n",
      "Epoch 96/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0404 - accuracy: 0.9875\n",
      "Epoch 00096: val_loss did not improve from 0.57753\n",
      "\n",
      "Epoch 00096: val_accuracy did not improve from 0.89268\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 0.0404 - accuracy: 0.9875 - val_loss: 1.3990 - val_accuracy: 0.8341\n",
      "Epoch 97/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0889 - accuracy: 0.9718\n",
      "Epoch 00097: val_loss did not improve from 0.57753\n",
      "\n",
      "Epoch 00097: val_accuracy did not improve from 0.89268\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 0.0889 - accuracy: 0.9718 - val_loss: 1.3056 - val_accuracy: 0.8537\n",
      "Epoch 98/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1249 - accuracy: 0.9756\n",
      "Epoch 00098: val_loss did not improve from 0.57753\n",
      "\n",
      "Epoch 00098: val_accuracy did not improve from 0.89268\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 0.1249 - accuracy: 0.9756 - val_loss: 1.4573 - val_accuracy: 0.8244\n",
      "Epoch 99/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0737 - accuracy: 0.9750\n",
      "Epoch 00099: val_loss did not improve from 0.57753\n",
      "\n",
      "Epoch 00099: val_accuracy did not improve from 0.89268\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 0.0737 - accuracy: 0.9750 - val_loss: 1.2017 - val_accuracy: 0.8585\n",
      "Epoch 100/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1152 - accuracy: 0.9740\n",
      "Epoch 00100: val_loss did not improve from 0.57753\n",
      "\n",
      "Epoch 00100: val_accuracy did not improve from 0.89268\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 0.1152 - accuracy: 0.9740 - val_loss: 0.8055 - val_accuracy: 0.8439\n",
      "Epoch 101/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1472 - accuracy: 0.9636\n",
      "Epoch 00101: val_loss did not improve from 0.57753\n",
      "\n",
      "Epoch 00101: val_accuracy did not improve from 0.89268\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 0.1472 - accuracy: 0.9636 - val_loss: 1.3101 - val_accuracy: 0.8000\n",
      "Epoch 102/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.2457 - accuracy: 0.9501\n",
      "Epoch 00102: val_loss did not improve from 0.57753\n",
      "\n",
      "Epoch 00102: val_accuracy did not improve from 0.89268\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 0.2457 - accuracy: 0.9501 - val_loss: 1.6133 - val_accuracy: 0.7902\n",
      "Epoch 103/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.2279 - accuracy: 0.9468\n",
      "Epoch 00103: val_loss did not improve from 0.57753\n",
      "\n",
      "Epoch 00103: val_accuracy did not improve from 0.89268\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 0.2279 - accuracy: 0.9468 - val_loss: 1.8354 - val_accuracy: 0.7659\n",
      "Epoch 104/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.2394 - accuracy: 0.9495\n",
      "Epoch 00104: val_loss did not improve from 0.57753\n",
      "\n",
      "Epoch 00104: val_accuracy did not improve from 0.89268\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 0.2394 - accuracy: 0.9495 - val_loss: 1.3854 - val_accuracy: 0.8293\n",
      "Epoch 105/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1520 - accuracy: 0.9636\n",
      "Epoch 00105: val_loss did not improve from 0.57753\n",
      "\n",
      "Epoch 00105: val_accuracy did not improve from 0.89268\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 0.1520 - accuracy: 0.9636 - val_loss: 1.9017 - val_accuracy: 0.7951\n",
      "Epoch 106/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0908 - accuracy: 0.9761\n",
      "Epoch 00106: val_loss did not improve from 0.57753\n",
      "\n",
      "Epoch 00106: val_accuracy did not improve from 0.89268\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 0.0908 - accuracy: 0.9761 - val_loss: 1.1091 - val_accuracy: 0.8488\n",
      "Epoch 107/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0495 - accuracy: 0.9913\n",
      "Epoch 00107: val_loss did not improve from 0.57753\n",
      "\n",
      "Epoch 00107: val_accuracy did not improve from 0.89268\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 0.0495 - accuracy: 0.9913 - val_loss: 0.9868 - val_accuracy: 0.8683\n",
      "Epoch 108/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0230 - accuracy: 0.9913\n",
      "Epoch 00108: val_loss did not improve from 0.57753\n",
      "\n",
      "Epoch 00108: val_accuracy improved from 0.89268 to 0.89756, saving model to ./home_models_0205\\02_04_AI_val_accuracy_index_1.h5\n",
      "58/58 [==============================] - 32s 550ms/step - loss: 0.0230 - accuracy: 0.9913 - val_loss: 0.8712 - val_accuracy: 0.8976\n",
      "Epoch 109/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0114 - accuracy: 0.9967\n",
      "Epoch 00109: val_loss did not improve from 0.57753\n",
      "\n",
      "Epoch 00109: val_accuracy did not improve from 0.89756\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 0.0114 - accuracy: 0.9967 - val_loss: 0.9655 - val_accuracy: 0.8293\n",
      "Epoch 110/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0172 - accuracy: 0.9951\n",
      "Epoch 00110: val_loss did not improve from 0.57753\n",
      "\n",
      "Epoch 00110: val_accuracy did not improve from 0.89756\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 0.0172 - accuracy: 0.9951 - val_loss: 1.1199 - val_accuracy: 0.8537\n",
      "Epoch 111/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0279 - accuracy: 0.9929\n",
      "Epoch 00111: val_loss did not improve from 0.57753\n",
      "\n",
      "Epoch 00111: ReduceLROnPlateau reducing learning rate to 0.001500000013038516.\n",
      "\n",
      "Epoch 00111: val_accuracy did not improve from 0.89756\n",
      "58/58 [==============================] - 17s 294ms/step - loss: 0.0279 - accuracy: 0.9929 - val_loss: 0.8303 - val_accuracy: 0.8634\n",
      "Epoch 112/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0098 - accuracy: 0.9957\n",
      "Epoch 00112: val_loss did not improve from 0.57753\n",
      "\n",
      "Epoch 00112: val_accuracy did not improve from 0.89756\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 0.0098 - accuracy: 0.9957 - val_loss: 0.9035 - val_accuracy: 0.8829\n",
      "Epoch 113/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 5.3844e-04 - accuracy: 1.0000\n",
      "Epoch 00113: val_loss did not improve from 0.57753\n",
      "\n",
      "Epoch 00113: val_accuracy did not improve from 0.89756\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 5.3844e-04 - accuracy: 1.0000 - val_loss: 0.9626 - val_accuracy: 0.8537\n",
      "Epoch 114/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 5.0806e-04 - accuracy: 1.0000\n",
      "Epoch 00114: val_loss did not improve from 0.57753\n",
      "\n",
      "Epoch 00114: val_accuracy did not improve from 0.89756\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 5.0806e-04 - accuracy: 1.0000 - val_loss: 0.8336 - val_accuracy: 0.8780\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 7.9341e-04 - accuracy: 0.9995\n",
      "Epoch 00115: val_loss did not improve from 0.57753\n",
      "\n",
      "Epoch 00115: val_accuracy improved from 0.89756 to 0.91220, saving model to ./home_models_0205\\02_04_AI_val_accuracy_index_1.h5\n",
      "58/58 [==============================] - 32s 548ms/step - loss: 7.9341e-04 - accuracy: 0.9995 - val_loss: 0.7826 - val_accuracy: 0.9122\n",
      "Epoch 116/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 1.6884e-04 - accuracy: 1.0000\n",
      "Epoch 00116: val_loss did not improve from 0.57753\n",
      "\n",
      "Epoch 00116: val_accuracy did not improve from 0.91220\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 1.6884e-04 - accuracy: 1.0000 - val_loss: 0.7732 - val_accuracy: 0.8878\n",
      "Epoch 117/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 1.9899e-04 - accuracy: 1.0000\n",
      "Epoch 00117: val_loss did not improve from 0.57753\n",
      "\n",
      "Epoch 00117: val_accuracy did not improve from 0.91220\n",
      "58/58 [==============================] - 17s 294ms/step - loss: 1.9899e-04 - accuracy: 1.0000 - val_loss: 0.7670 - val_accuracy: 0.9024\n",
      "Epoch 118/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 2.7269e-04 - accuracy: 1.0000\n",
      "Epoch 00118: val_loss did not improve from 0.57753\n",
      "\n",
      "Epoch 00118: val_accuracy did not improve from 0.91220\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 2.7269e-04 - accuracy: 1.0000 - val_loss: 0.7633 - val_accuracy: 0.8829\n",
      "Epoch 119/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 5.5296e-04 - accuracy: 1.0000\n",
      "Epoch 00119: val_loss did not improve from 0.57753\n",
      "\n",
      "Epoch 00119: val_accuracy did not improve from 0.91220\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 5.5296e-04 - accuracy: 1.0000 - val_loss: 0.7442 - val_accuracy: 0.8878\n",
      "Epoch 120/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 8.9661e-05 - accuracy: 1.0000\n",
      "Epoch 00120: val_loss did not improve from 0.57753\n",
      "\n",
      "Epoch 00120: val_accuracy did not improve from 0.91220\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 8.9661e-05 - accuracy: 1.0000 - val_loss: 0.7156 - val_accuracy: 0.8927\n",
      "Epoch 121/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 1.5772e-04 - accuracy: 1.0000\n",
      "Epoch 00121: val_loss did not improve from 0.57753\n",
      "\n",
      "Epoch 00121: val_accuracy did not improve from 0.91220\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 1.5772e-04 - accuracy: 1.0000 - val_loss: 0.8975 - val_accuracy: 0.8634\n",
      "Epoch 122/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 6.1791e-04 - accuracy: 1.0000\n",
      "Epoch 00122: val_loss did not improve from 0.57753\n",
      "\n",
      "Epoch 00122: val_accuracy did not improve from 0.91220\n",
      "58/58 [==============================] - 17s 296ms/step - loss: 6.1791e-04 - accuracy: 1.0000 - val_loss: 0.7588 - val_accuracy: 0.8829\n",
      "Epoch 123/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 1.4030e-04 - accuracy: 1.0000\n",
      "Epoch 00123: val_loss did not improve from 0.57753\n",
      "\n",
      "Epoch 00123: val_accuracy did not improve from 0.91220\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 1.4030e-04 - accuracy: 1.0000 - val_loss: 0.7036 - val_accuracy: 0.8780\n",
      "Epoch 124/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 6.9008e-05 - accuracy: 1.0000\n",
      "Epoch 00124: val_loss did not improve from 0.57753\n",
      "\n",
      "Epoch 00124: val_accuracy did not improve from 0.91220\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 6.9008e-05 - accuracy: 1.0000 - val_loss: 0.7178 - val_accuracy: 0.8780\n",
      "Epoch 125/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 7.2095e-05 - accuracy: 1.0000\n",
      "Epoch 00125: val_loss did not improve from 0.57753\n",
      "\n",
      "Epoch 00125: val_accuracy did not improve from 0.91220\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 7.2095e-05 - accuracy: 1.0000 - val_loss: 0.8317 - val_accuracy: 0.8683\n",
      "Epoch 126/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 3.7231e-05 - accuracy: 1.0000\n",
      "Epoch 00126: val_loss did not improve from 0.57753\n",
      "\n",
      "Epoch 00126: val_accuracy did not improve from 0.91220\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 3.7231e-05 - accuracy: 1.0000 - val_loss: 0.6634 - val_accuracy: 0.8878\n",
      "Epoch 127/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 3.2596e-05 - accuracy: 1.0000\n",
      "Epoch 00127: val_loss did not improve from 0.57753\n",
      "\n",
      "Epoch 00127: val_accuracy did not improve from 0.91220\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 3.2596e-05 - accuracy: 1.0000 - val_loss: 0.7816 - val_accuracy: 0.8732\n",
      "Epoch 128/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 4.7096e-05 - accuracy: 1.0000\n",
      "Epoch 00128: val_loss did not improve from 0.57753\n",
      "\n",
      "Epoch 00128: val_accuracy did not improve from 0.91220\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 4.7096e-05 - accuracy: 1.0000 - val_loss: 0.7471 - val_accuracy: 0.8780\n",
      "Epoch 129/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 8.6136e-05 - accuracy: 1.0000\n",
      "Epoch 00129: val_loss did not improve from 0.57753\n",
      "\n",
      "Epoch 00129: val_accuracy did not improve from 0.91220\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 8.6136e-05 - accuracy: 1.0000 - val_loss: 0.7477 - val_accuracy: 0.8829\n",
      "Epoch 130/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 8.8894e-05 - accuracy: 1.0000\n",
      "Epoch 00130: val_loss did not improve from 0.57753\n",
      "\n",
      "Epoch 00130: val_accuracy did not improve from 0.91220\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 8.8894e-05 - accuracy: 1.0000 - val_loss: 0.7729 - val_accuracy: 0.8829\n",
      "Epoch 131/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 7.3139e-05 - accuracy: 1.0000\n",
      "Epoch 00131: val_loss did not improve from 0.57753\n",
      "\n",
      "Epoch 00131: val_accuracy did not improve from 0.91220\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 7.3139e-05 - accuracy: 1.0000 - val_loss: 0.7339 - val_accuracy: 0.8780\n",
      "Epoch 132/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 1.4188e-04 - accuracy: 1.0000\n",
      "Epoch 00132: val_loss did not improve from 0.57753\n",
      "\n",
      "Epoch 00132: val_accuracy did not improve from 0.91220\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 1.4188e-04 - accuracy: 1.0000 - val_loss: 0.7265 - val_accuracy: 0.8634\n",
      "Epoch 133/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 2.9803e-05 - accuracy: 1.0000\n",
      "Epoch 00133: val_loss did not improve from 0.57753\n",
      "\n",
      "Epoch 00133: val_accuracy did not improve from 0.91220\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 2.9803e-05 - accuracy: 1.0000 - val_loss: 0.7648 - val_accuracy: 0.8732\n",
      "Epoch 134/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 4.1504e-05 - accuracy: 1.0000\n",
      "Epoch 00134: val_loss did not improve from 0.57753\n",
      "\n",
      "Epoch 00134: val_accuracy did not improve from 0.91220\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 4.1504e-05 - accuracy: 1.0000 - val_loss: 0.7855 - val_accuracy: 0.8780\n",
      "Epoch 135/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 2.9565e-05 - accuracy: 1.0000\n",
      "Epoch 00135: val_loss did not improve from 0.57753\n",
      "\n",
      "Epoch 00135: val_accuracy did not improve from 0.91220\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 2.9565e-05 - accuracy: 1.0000 - val_loss: 0.8427 - val_accuracy: 0.8488\n",
      "Epoch 136/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 5.8601e-05 - accuracy: 1.0000\n",
      "Epoch 00136: val_loss did not improve from 0.57753\n",
      "\n",
      "Epoch 00136: val_accuracy did not improve from 0.91220\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 5.8601e-05 - accuracy: 1.0000 - val_loss: 0.6062 - val_accuracy: 0.8927\n",
      "Epoch 137/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 4.6021e-04 - accuracy: 1.0000\n",
      "Epoch 00137: val_loss did not improve from 0.57753\n",
      "\n",
      "Epoch 00137: val_accuracy did not improve from 0.91220\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 4.6021e-04 - accuracy: 1.0000 - val_loss: 0.7233 - val_accuracy: 0.8927\n",
      "Epoch 138/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 8.6189e-05 - accuracy: 1.0000\n",
      "Epoch 00138: val_loss did not improve from 0.57753\n",
      "\n",
      "Epoch 00138: val_accuracy did not improve from 0.91220\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 8.6189e-05 - accuracy: 1.0000 - val_loss: 0.7076 - val_accuracy: 0.8683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 139/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 3.4550e-05 - accuracy: 1.0000\n",
      "Epoch 00139: val_loss did not improve from 0.57753\n",
      "\n",
      "Epoch 00139: val_accuracy did not improve from 0.91220\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 3.4550e-05 - accuracy: 1.0000 - val_loss: 0.6137 - val_accuracy: 0.8732\n",
      "Epoch 140/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 4.3005e-05 - accuracy: 1.0000\n",
      "Epoch 00140: val_loss did not improve from 0.57753\n",
      "\n",
      "Epoch 00140: val_accuracy did not improve from 0.91220\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 4.3005e-05 - accuracy: 1.0000 - val_loss: 0.7075 - val_accuracy: 0.8634\n",
      "Epoch 141/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 3.2414e-05 - accuracy: 1.0000\n",
      "Epoch 00141: val_loss did not improve from 0.57753\n",
      "\n",
      "Epoch 00141: val_accuracy did not improve from 0.91220\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 3.2414e-05 - accuracy: 1.0000 - val_loss: 0.7146 - val_accuracy: 0.8829\n",
      "Epoch 142/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 2.5023e-05 - accuracy: 1.0000\n",
      "Epoch 00142: val_loss did not improve from 0.57753\n",
      "\n",
      "Epoch 00142: val_accuracy did not improve from 0.91220\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 2.5023e-05 - accuracy: 1.0000 - val_loss: 0.7149 - val_accuracy: 0.8780\n",
      "Epoch 143/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 2.8528e-05 - accuracy: 1.0000\n",
      "Epoch 00143: val_loss did not improve from 0.57753\n",
      "\n",
      "Epoch 00143: val_accuracy did not improve from 0.91220\n",
      "58/58 [==============================] - 17s 294ms/step - loss: 2.8528e-05 - accuracy: 1.0000 - val_loss: 0.8878 - val_accuracy: 0.8732\n",
      "Epoch 144/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 3.7965e-05 - accuracy: 1.0000\n",
      "Epoch 00144: val_loss did not improve from 0.57753\n",
      "\n",
      "Epoch 00144: val_accuracy did not improve from 0.91220\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 3.7965e-05 - accuracy: 1.0000 - val_loss: 0.8050 - val_accuracy: 0.8634\n",
      "Epoch 145/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 1.3943e-05 - accuracy: 1.0000\n",
      "Epoch 00145: val_loss did not improve from 0.57753\n",
      "\n",
      "Epoch 00145: val_accuracy did not improve from 0.91220\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 1.3943e-05 - accuracy: 1.0000 - val_loss: 0.7081 - val_accuracy: 0.8829\n",
      "Epoch 146/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 1.0273e-04 - accuracy: 1.0000\n",
      "Epoch 00146: val_loss did not improve from 0.57753\n",
      "\n",
      "Epoch 00146: val_accuracy did not improve from 0.91220\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 1.0273e-04 - accuracy: 1.0000 - val_loss: 0.7559 - val_accuracy: 0.8732\n",
      "Epoch 147/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 2.6045e-05 - accuracy: 1.0000\n",
      "Epoch 00147: val_loss did not improve from 0.57753\n",
      "\n",
      "Epoch 00147: val_accuracy did not improve from 0.91220\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 2.6045e-05 - accuracy: 1.0000 - val_loss: 0.7198 - val_accuracy: 0.8634\n",
      "Epoch 148/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 3.1319e-05 - accuracy: 1.0000\n",
      "Epoch 00148: val_loss did not improve from 0.57753\n",
      "\n",
      "Epoch 00148: val_accuracy did not improve from 0.91220\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 3.1319e-05 - accuracy: 1.0000 - val_loss: 0.6336 - val_accuracy: 0.8780\n",
      "Epoch 149/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 2.2704e-05 - accuracy: 1.0000\n",
      "Epoch 00149: val_loss did not improve from 0.57753\n",
      "\n",
      "Epoch 00149: val_accuracy did not improve from 0.91220\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 2.2704e-05 - accuracy: 1.0000 - val_loss: 0.7153 - val_accuracy: 0.8829\n",
      "Epoch 150/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 3.0462e-05 - accuracy: 1.0000\n",
      "Epoch 00150: val_loss did not improve from 0.57753\n",
      "\n",
      "Epoch 00150: val_accuracy did not improve from 0.91220\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 3.0462e-05 - accuracy: 1.0000 - val_loss: 0.7891 - val_accuracy: 0.8683\n",
      "Epoch 151/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 1.7935e-05 - accuracy: 1.0000\n",
      "Epoch 00151: val_loss did not improve from 0.57753\n",
      "\n",
      "Epoch 00151: ReduceLROnPlateau reducing learning rate to 0.000750000006519258.\n",
      "\n",
      "Epoch 00151: val_accuracy did not improve from 0.91220\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 1.7935e-05 - accuracy: 1.0000 - val_loss: 0.8034 - val_accuracy: 0.8634\n",
      "Epoch 152/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 1.8425e-05 - accuracy: 1.0000\n",
      "Epoch 00152: val_loss did not improve from 0.57753\n",
      "\n",
      "Epoch 00152: val_accuracy did not improve from 0.91220\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 1.8425e-05 - accuracy: 1.0000 - val_loss: 0.6111 - val_accuracy: 0.8927\n",
      "Epoch 153/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 1.9431e-05 - accuracy: 1.0000\n",
      "Epoch 00153: val_loss did not improve from 0.57753\n",
      "\n",
      "Epoch 00153: val_accuracy did not improve from 0.91220\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 1.9431e-05 - accuracy: 1.0000 - val_loss: 0.6793 - val_accuracy: 0.8878\n",
      "Epoch 154/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 1.2146e-05 - accuracy: 1.0000\n",
      "Epoch 00154: val_loss did not improve from 0.57753\n",
      "\n",
      "Epoch 00154: val_accuracy did not improve from 0.91220\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 1.2146e-05 - accuracy: 1.0000 - val_loss: 0.8535 - val_accuracy: 0.8634\n",
      "Epoch 155/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 1.7144e-04 - accuracy: 1.0000\n",
      "Epoch 00155: val_loss did not improve from 0.57753\n",
      "\n",
      "Epoch 00155: val_accuracy did not improve from 0.91220\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 1.7144e-04 - accuracy: 1.0000 - val_loss: 0.6186 - val_accuracy: 0.8927\n",
      "Epoch 156/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 3.5460e-05 - accuracy: 1.0000\n",
      "Epoch 00156: val_loss did not improve from 0.57753\n",
      "\n",
      "Epoch 00156: val_accuracy did not improve from 0.91220\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 3.5460e-05 - accuracy: 1.0000 - val_loss: 0.7297 - val_accuracy: 0.8780\n",
      "Epoch 157/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 2.0923e-05 - accuracy: 1.0000\n",
      "Epoch 00157: val_loss did not improve from 0.57753\n",
      "\n",
      "Epoch 00157: val_accuracy did not improve from 0.91220\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 2.0923e-05 - accuracy: 1.0000 - val_loss: 0.6977 - val_accuracy: 0.8829\n",
      "Epoch 158/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 1.4886e-05 - accuracy: 1.0000\n",
      "Epoch 00158: val_loss did not improve from 0.57753\n",
      "\n",
      "Epoch 00158: val_accuracy did not improve from 0.91220\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 1.4886e-05 - accuracy: 1.0000 - val_loss: 0.6560 - val_accuracy: 0.8829\n",
      "Epoch 159/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 6.6882e-05 - accuracy: 1.0000\n",
      "Epoch 00159: val_loss did not improve from 0.57753\n",
      "\n",
      "Epoch 00159: val_accuracy did not improve from 0.91220\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 6.6882e-05 - accuracy: 1.0000 - val_loss: 0.6993 - val_accuracy: 0.8634\n",
      "Epoch 160/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 1.3981e-05 - accuracy: 1.0000\n",
      "Epoch 00160: val_loss did not improve from 0.57753\n",
      "\n",
      "Epoch 00160: val_accuracy did not improve from 0.91220\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 1.3981e-05 - accuracy: 1.0000 - val_loss: 0.6976 - val_accuracy: 0.8780\n",
      "Epoch 161/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 4.6046e-05 - accuracy: 1.0000\n",
      "Epoch 00161: val_loss did not improve from 0.57753\n",
      "\n",
      "Epoch 00161: val_accuracy did not improve from 0.91220\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 4.6046e-05 - accuracy: 1.0000 - val_loss: 0.7485 - val_accuracy: 0.8732\n",
      "Epoch 162/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 1.2629e-05 - accuracy: 1.0000\n",
      "Epoch 00162: val_loss did not improve from 0.57753\n",
      "\n",
      "Epoch 00162: val_accuracy did not improve from 0.91220\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 1.2629e-05 - accuracy: 1.0000 - val_loss: 0.6896 - val_accuracy: 0.8634\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 163/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 1.4099e-05 - accuracy: 1.0000\n",
      "Epoch 00163: val_loss did not improve from 0.57753\n",
      "\n",
      "Epoch 00163: val_accuracy did not improve from 0.91220\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 1.4099e-05 - accuracy: 1.0000 - val_loss: 0.6520 - val_accuracy: 0.8585\n",
      "Epoch 164/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 1.6091e-05 - accuracy: 1.0000\n",
      "Epoch 00164: val_loss did not improve from 0.57753\n",
      "\n",
      "Epoch 00164: val_accuracy did not improve from 0.91220\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 1.6091e-05 - accuracy: 1.0000 - val_loss: 0.6122 - val_accuracy: 0.8634\n",
      "Epoch 165/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 1.3454e-05 - accuracy: 1.0000\n",
      "Epoch 00165: val_loss did not improve from 0.57753\n",
      "\n",
      "Epoch 00165: val_accuracy did not improve from 0.91220\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 1.3454e-05 - accuracy: 1.0000 - val_loss: 0.8475 - val_accuracy: 0.8585\n",
      "Epoch 166/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 1.6233e-05 - accuracy: 1.0000\n",
      "Epoch 00166: val_loss did not improve from 0.57753\n",
      "\n",
      "Epoch 00166: val_accuracy did not improve from 0.91220\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 1.6233e-05 - accuracy: 1.0000 - val_loss: 0.7822 - val_accuracy: 0.8634\n",
      "Epoch 167/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 2.9241e-05 - accuracy: 1.0000\n",
      "Epoch 00167: val_loss did not improve from 0.57753\n",
      "\n",
      "Epoch 00167: val_accuracy did not improve from 0.91220\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 2.9241e-05 - accuracy: 1.0000 - val_loss: 0.7516 - val_accuracy: 0.8634\n",
      "Epoch 168/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 1.2194e-05 - accuracy: 1.0000\n",
      "Epoch 00168: val_loss did not improve from 0.57753\n",
      "\n",
      "Epoch 00168: val_accuracy did not improve from 0.91220\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 1.2194e-05 - accuracy: 1.0000 - val_loss: 0.7212 - val_accuracy: 0.8829\n",
      "Epoch 169/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 1.1937e-05 - accuracy: 1.0000\n",
      "Epoch 00169: val_loss did not improve from 0.57753\n",
      "\n",
      "Epoch 00169: val_accuracy did not improve from 0.91220\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 1.1937e-05 - accuracy: 1.0000 - val_loss: 0.5818 - val_accuracy: 0.8927\n",
      "Epoch 170/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 1.1599e-05 - accuracy: 1.0000\n",
      "Epoch 00170: val_loss did not improve from 0.57753\n",
      "\n",
      "Epoch 00170: val_accuracy did not improve from 0.91220\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 1.1599e-05 - accuracy: 1.0000 - val_loss: 0.6725 - val_accuracy: 0.8732\n",
      "Epoch 171/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 8.5218e-06 - accuracy: 1.0000\n",
      "Epoch 00171: val_loss did not improve from 0.57753\n",
      "\n",
      "Epoch 00171: val_accuracy did not improve from 0.91220\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 8.5218e-06 - accuracy: 1.0000 - val_loss: 0.6679 - val_accuracy: 0.8732\n",
      "1  번째 학습을 완료했습니다.\n",
      "Epoch 1/2000\n",
      " 2/58 [>.............................] - ETA: 8s - loss: 33.8839 - accuracy: 0.0625WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1089s vs `on_train_batch_end` time: 0.1875s). Check your callbacks.\n",
      "58/58 [==============================] - ETA: 0s - loss: 15.3316 - accuracy: 0.1129\n",
      "Epoch 00001: val_loss improved from inf to 1802.83887, saving model to ./home_models_0205\\02_04_AI_val_loss_index_2.h5\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.10244, saving model to ./home_models_0205\\02_04_AI_val_accuracy_index_2.h5\n",
      "58/58 [==============================] - 21s 365ms/step - loss: 15.3316 - accuracy: 0.1129 - val_loss: 1802.8389 - val_accuracy: 0.1024\n",
      "Epoch 2/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 2.4795 - accuracy: 0.1248\n",
      "Epoch 00002: val_loss improved from 1802.83887 to 217.96379, saving model to ./home_models_0205\\02_04_AI_val_loss_index_2.h5\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.10244 to 0.12683, saving model to ./home_models_0205\\02_04_AI_val_accuracy_index_2.h5\n",
      "58/58 [==============================] - 21s 363ms/step - loss: 2.4795 - accuracy: 0.1248 - val_loss: 217.9638 - val_accuracy: 0.1268\n",
      "Epoch 3/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 2.3325 - accuracy: 0.1574\n",
      "Epoch 00003: val_loss improved from 217.96379 to 48.54155, saving model to ./home_models_0205\\02_04_AI_val_loss_index_2.h5\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.12683\n",
      "58/58 [==============================] - 19s 331ms/step - loss: 2.3325 - accuracy: 0.1574 - val_loss: 48.5415 - val_accuracy: 0.1220\n",
      "Epoch 4/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 2.2955 - accuracy: 0.1959\n",
      "Epoch 00004: val_loss improved from 48.54155 to 3.53227, saving model to ./home_models_0205\\02_04_AI_val_loss_index_2.h5\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.12683\n",
      "58/58 [==============================] - 19s 321ms/step - loss: 2.2955 - accuracy: 0.1959 - val_loss: 3.5323 - val_accuracy: 0.1122\n",
      "Epoch 5/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 2.2763 - accuracy: 0.2333\n",
      "Epoch 00005: val_loss improved from 3.53227 to 2.97160, saving model to ./home_models_0205\\02_04_AI_val_loss_index_2.h5\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.12683\n",
      "58/58 [==============================] - 19s 328ms/step - loss: 2.2763 - accuracy: 0.2333 - val_loss: 2.9716 - val_accuracy: 0.0732\n",
      "Epoch 6/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 2.0160 - accuracy: 0.3114\n",
      "Epoch 00006: val_loss improved from 2.97160 to 2.87812, saving model to ./home_models_0205\\02_04_AI_val_loss_index_2.h5\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.12683\n",
      "58/58 [==============================] - 19s 332ms/step - loss: 2.0160 - accuracy: 0.3114 - val_loss: 2.8781 - val_accuracy: 0.0976\n",
      "Epoch 7/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 1.8501 - accuracy: 0.3614\n",
      "Epoch 00007: val_loss improved from 2.87812 to 2.87151, saving model to ./home_models_0205\\02_04_AI_val_loss_index_2.h5\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.12683\n",
      "58/58 [==============================] - 19s 329ms/step - loss: 1.8501 - accuracy: 0.3614 - val_loss: 2.8715 - val_accuracy: 0.0927\n",
      "Epoch 8/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 1.7388 - accuracy: 0.3993\n",
      "Epoch 00008: val_loss did not improve from 2.87151\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.12683\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 1.7388 - accuracy: 0.3993 - val_loss: 2.9166 - val_accuracy: 0.1171\n",
      "Epoch 9/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 1.5968 - accuracy: 0.4476\n",
      "Epoch 00009: val_loss improved from 2.87151 to 2.62713, saving model to ./home_models_0205\\02_04_AI_val_loss_index_2.h5\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.12683 to 0.15122, saving model to ./home_models_0205\\02_04_AI_val_accuracy_index_2.h5\n",
      "58/58 [==============================] - 50s 869ms/step - loss: 1.5968 - accuracy: 0.4476 - val_loss: 2.6271 - val_accuracy: 0.1512\n",
      "Epoch 10/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 1.4256 - accuracy: 0.5133\n",
      "Epoch 00010: val_loss did not improve from 2.62713\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.15122\n",
      "58/58 [==============================] - 17s 294ms/step - loss: 1.4256 - accuracy: 0.5133 - val_loss: 3.1284 - val_accuracy: 0.1512\n",
      "Epoch 11/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 1.2226 - accuracy: 0.5751\n",
      "Epoch 00011: val_loss improved from 2.62713 to 1.55935, saving model to ./home_models_0205\\02_04_AI_val_loss_index_2.h5\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.15122 to 0.44390, saving model to ./home_models_0205\\02_04_AI_val_accuracy_index_2.h5\n",
      "58/58 [==============================] - 49s 843ms/step - loss: 1.2226 - accuracy: 0.5751 - val_loss: 1.5594 - val_accuracy: 0.4439\n",
      "Epoch 12/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 1.2100 - accuracy: 0.6061\n",
      "Epoch 00012: val_loss did not improve from 1.55935\n",
      "\n",
      "Epoch 00012: val_accuracy improved from 0.44390 to 0.49756, saving model to ./home_models_0205\\02_04_AI_val_accuracy_index_2.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58/58 [==============================] - 19s 330ms/step - loss: 1.2100 - accuracy: 0.6061 - val_loss: 1.6730 - val_accuracy: 0.4976\n",
      "Epoch 13/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.9917 - accuracy: 0.6517\n",
      "Epoch 00013: val_loss improved from 1.55935 to 1.40794, saving model to ./home_models_0205\\02_04_AI_val_loss_index_2.h5\n",
      "\n",
      "Epoch 00013: val_accuracy improved from 0.49756 to 0.54146, saving model to ./home_models_0205\\02_04_AI_val_accuracy_index_2.h5\n",
      "58/58 [==============================] - 48s 819ms/step - loss: 0.9917 - accuracy: 0.6517 - val_loss: 1.4079 - val_accuracy: 0.5415\n",
      "Epoch 14/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.9723 - accuracy: 0.6820\n",
      "Epoch 00014: val_loss did not improve from 1.40794\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.54146\n",
      "58/58 [==============================] - 17s 294ms/step - loss: 0.9723 - accuracy: 0.6820 - val_loss: 2.0366 - val_accuracy: 0.4585\n",
      "Epoch 15/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.7602 - accuracy: 0.7455\n",
      "Epoch 00015: val_loss improved from 1.40794 to 1.27086, saving model to ./home_models_0205\\02_04_AI_val_loss_index_2.h5\n",
      "\n",
      "Epoch 00015: val_accuracy improved from 0.54146 to 0.60488, saving model to ./home_models_0205\\02_04_AI_val_accuracy_index_2.h5\n",
      "58/58 [==============================] - 47s 815ms/step - loss: 0.7602 - accuracy: 0.7455 - val_loss: 1.2709 - val_accuracy: 0.6049\n",
      "Epoch 16/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.7668 - accuracy: 0.7428\n",
      "Epoch 00016: val_loss did not improve from 1.27086\n",
      "\n",
      "Epoch 00016: val_accuracy improved from 0.60488 to 0.62927, saving model to ./home_models_0205\\02_04_AI_val_accuracy_index_2.h5\n",
      "58/58 [==============================] - 19s 327ms/step - loss: 0.7668 - accuracy: 0.7428 - val_loss: 1.4131 - val_accuracy: 0.6293\n",
      "Epoch 17/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.6732 - accuracy: 0.7689\n",
      "Epoch 00017: val_loss improved from 1.27086 to 1.13222, saving model to ./home_models_0205\\02_04_AI_val_loss_index_2.h5\n",
      "\n",
      "Epoch 00017: val_accuracy improved from 0.62927 to 0.64390, saving model to ./home_models_0205\\02_04_AI_val_accuracy_index_2.h5\n",
      "58/58 [==============================] - 49s 839ms/step - loss: 0.6732 - accuracy: 0.7689 - val_loss: 1.1322 - val_accuracy: 0.6439\n",
      "Epoch 18/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.5831 - accuracy: 0.8020\n",
      "Epoch 00018: val_loss did not improve from 1.13222\n",
      "\n",
      "Epoch 00018: val_accuracy improved from 0.64390 to 0.69268, saving model to ./home_models_0205\\02_04_AI_val_accuracy_index_2.h5\n",
      "58/58 [==============================] - 19s 329ms/step - loss: 0.5831 - accuracy: 0.8020 - val_loss: 1.1930 - val_accuracy: 0.6927\n",
      "Epoch 19/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.5192 - accuracy: 0.8313\n",
      "Epoch 00019: val_loss did not improve from 1.13222\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.69268\n",
      "58/58 [==============================] - 17s 294ms/step - loss: 0.5192 - accuracy: 0.8313 - val_loss: 3.2006 - val_accuracy: 0.3512\n",
      "Epoch 20/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.5350 - accuracy: 0.8280\n",
      "Epoch 00020: val_loss did not improve from 1.13222\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.69268\n",
      "58/58 [==============================] - 17s 294ms/step - loss: 0.5350 - accuracy: 0.8280 - val_loss: 6.5385 - val_accuracy: 0.2537\n",
      "Epoch 21/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.4882 - accuracy: 0.8345\n",
      "Epoch 00021: val_loss did not improve from 1.13222\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.69268\n",
      "58/58 [==============================] - 17s 294ms/step - loss: 0.4882 - accuracy: 0.8345 - val_loss: 3.3831 - val_accuracy: 0.4000\n",
      "Epoch 22/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.4139 - accuracy: 0.8644\n",
      "Epoch 00022: val_loss did not improve from 1.13222\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.69268\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 0.4139 - accuracy: 0.8644 - val_loss: 1.5184 - val_accuracy: 0.6146\n",
      "Epoch 23/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.3930 - accuracy: 0.8774\n",
      "Epoch 00023: val_loss did not improve from 1.13222\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.69268\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 0.3930 - accuracy: 0.8774 - val_loss: 1.2687 - val_accuracy: 0.6341\n",
      "Epoch 24/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.4746 - accuracy: 0.8421\n",
      "Epoch 00024: val_loss did not improve from 1.13222\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.69268\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 0.4746 - accuracy: 0.8421 - val_loss: 2.8175 - val_accuracy: 0.4878\n",
      "Epoch 25/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.3416 - accuracy: 0.8757\n",
      "Epoch 00025: val_loss did not improve from 1.13222\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.69268\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 0.3416 - accuracy: 0.8757 - val_loss: 1.2779 - val_accuracy: 0.6927\n",
      "Epoch 26/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.3493 - accuracy: 0.8741\n",
      "Epoch 00026: val_loss did not improve from 1.13222\n",
      "\n",
      "Epoch 00026: val_accuracy improved from 0.69268 to 0.71220, saving model to ./home_models_0205\\02_04_AI_val_accuracy_index_2.h5\n",
      "58/58 [==============================] - 33s 562ms/step - loss: 0.3493 - accuracy: 0.8741 - val_loss: 1.5658 - val_accuracy: 0.7122\n",
      "Epoch 27/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.3346 - accuracy: 0.8915\n",
      "Epoch 00027: val_loss did not improve from 1.13222\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.71220\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 0.3346 - accuracy: 0.8915 - val_loss: 1.3703 - val_accuracy: 0.6488\n",
      "Epoch 28/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.2566 - accuracy: 0.9099\n",
      "Epoch 00028: val_loss did not improve from 1.13222\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.71220\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 0.2566 - accuracy: 0.9099 - val_loss: 1.3549 - val_accuracy: 0.6049\n",
      "Epoch 29/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1904 - accuracy: 0.9354\n",
      "Epoch 00029: val_loss did not improve from 1.13222\n",
      "\n",
      "Epoch 00029: val_accuracy improved from 0.71220 to 0.74146, saving model to ./home_models_0205\\02_04_AI_val_accuracy_index_2.h5\n",
      "58/58 [==============================] - 32s 555ms/step - loss: 0.1904 - accuracy: 0.9354 - val_loss: 1.1335 - val_accuracy: 0.7415\n",
      "Epoch 30/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.2200 - accuracy: 0.9305\n",
      "Epoch 00030: val_loss improved from 1.13222 to 1.07879, saving model to ./home_models_0205\\02_04_AI_val_loss_index_2.h5\n",
      "\n",
      "Epoch 00030: val_accuracy improved from 0.74146 to 0.75122, saving model to ./home_models_0205\\02_04_AI_val_accuracy_index_2.h5\n",
      "58/58 [==============================] - 48s 830ms/step - loss: 0.2200 - accuracy: 0.9305 - val_loss: 1.0788 - val_accuracy: 0.7512\n",
      "Epoch 31/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.2892 - accuracy: 0.9110\n",
      "Epoch 00031: val_loss did not improve from 1.07879\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.75122\n",
      "58/58 [==============================] - 17s 294ms/step - loss: 0.2892 - accuracy: 0.9110 - val_loss: 1.8117 - val_accuracy: 0.6098\n",
      "Epoch 32/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1555 - accuracy: 0.9441\n",
      "Epoch 00032: val_loss did not improve from 1.07879\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.75122\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 0.1555 - accuracy: 0.9441 - val_loss: 1.0996 - val_accuracy: 0.7268\n",
      "Epoch 33/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.2094 - accuracy: 0.9354\n",
      "Epoch 00033: val_loss did not improve from 1.07879\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.75122\n",
      "58/58 [==============================] - 17s 294ms/step - loss: 0.2094 - accuracy: 0.9354 - val_loss: 3.4392 - val_accuracy: 0.4341\n",
      "Epoch 34/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.2055 - accuracy: 0.9338\n",
      "Epoch 00034: val_loss did not improve from 1.07879\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.75122\n",
      "58/58 [==============================] - 17s 294ms/step - loss: 0.2055 - accuracy: 0.9338 - val_loss: 1.3092 - val_accuracy: 0.7024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.3307 - accuracy: 0.8974\n",
      "Epoch 00035: val_loss did not improve from 1.07879\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.75122\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 0.3307 - accuracy: 0.8974 - val_loss: 4.3027 - val_accuracy: 0.4634\n",
      "Epoch 36/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.2843 - accuracy: 0.9181\n",
      "Epoch 00036: val_loss did not improve from 1.07879\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.75122\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 0.2843 - accuracy: 0.9181 - val_loss: 5.9306 - val_accuracy: 0.2293\n",
      "Epoch 37/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1969 - accuracy: 0.9349\n",
      "Epoch 00037: val_loss did not improve from 1.07879\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.75122\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 0.1969 - accuracy: 0.9349 - val_loss: 2.9758 - val_accuracy: 0.4878\n",
      "Epoch 38/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1274 - accuracy: 0.9598\n",
      "Epoch 00038: val_loss improved from 1.07879 to 1.06812, saving model to ./home_models_0205\\02_04_AI_val_loss_index_2.h5\n",
      "\n",
      "Epoch 00038: val_accuracy improved from 0.75122 to 0.78049, saving model to ./home_models_0205\\02_04_AI_val_accuracy_index_2.h5\n",
      "58/58 [==============================] - 48s 830ms/step - loss: 0.1274 - accuracy: 0.9598 - val_loss: 1.0681 - val_accuracy: 0.7805\n",
      "Epoch 39/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1555 - accuracy: 0.9474\n",
      "Epoch 00039: val_loss improved from 1.06812 to 1.06495, saving model to ./home_models_0205\\02_04_AI_val_loss_index_2.h5\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.78049\n",
      "58/58 [==============================] - 19s 334ms/step - loss: 0.1555 - accuracy: 0.9474 - val_loss: 1.0649 - val_accuracy: 0.7463\n",
      "Epoch 40/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1122 - accuracy: 0.9609\n",
      "Epoch 00040: val_loss did not improve from 1.06495\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.78049\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 0.1122 - accuracy: 0.9609 - val_loss: 1.2527 - val_accuracy: 0.7707\n",
      "Epoch 41/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1001 - accuracy: 0.9658\n",
      "Epoch 00041: val_loss improved from 1.06495 to 0.87949, saving model to ./home_models_0205\\02_04_AI_val_loss_index_2.h5\n",
      "\n",
      "Epoch 00041: val_accuracy improved from 0.78049 to 0.80976, saving model to ./home_models_0205\\02_04_AI_val_accuracy_index_2.h5\n",
      "58/58 [==============================] - 49s 838ms/step - loss: 0.1001 - accuracy: 0.9658 - val_loss: 0.8795 - val_accuracy: 0.8098\n",
      "Epoch 42/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1176 - accuracy: 0.9577\n",
      "Epoch 00042: val_loss did not improve from 0.87949\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.80976\n",
      "58/58 [==============================] - 17s 294ms/step - loss: 0.1176 - accuracy: 0.9577 - val_loss: 1.0435 - val_accuracy: 0.7854\n",
      "Epoch 43/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1645 - accuracy: 0.9495\n",
      "Epoch 00043: val_loss did not improve from 0.87949\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.80976\n",
      "58/58 [==============================] - 17s 294ms/step - loss: 0.1645 - accuracy: 0.9495 - val_loss: 2.0613 - val_accuracy: 0.6195\n",
      "Epoch 44/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.3001 - accuracy: 0.9159\n",
      "Epoch 00044: val_loss did not improve from 0.87949\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.80976\n",
      "58/58 [==============================] - 17s 294ms/step - loss: 0.3001 - accuracy: 0.9159 - val_loss: 1.4741 - val_accuracy: 0.7463\n",
      "Epoch 45/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.2492 - accuracy: 0.9230\n",
      "Epoch 00045: val_loss did not improve from 0.87949\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.80976\n",
      "58/58 [==============================] - 17s 294ms/step - loss: 0.2492 - accuracy: 0.9230 - val_loss: 1.6952 - val_accuracy: 0.7122\n",
      "Epoch 46/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.2364 - accuracy: 0.9289\n",
      "Epoch 00046: val_loss did not improve from 0.87949\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.80976\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 0.2364 - accuracy: 0.9289 - val_loss: 3.6128 - val_accuracy: 0.4976\n",
      "Epoch 47/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1494 - accuracy: 0.9479\n",
      "Epoch 00047: val_loss did not improve from 0.87949\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.80976\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 0.1494 - accuracy: 0.9479 - val_loss: 1.3166 - val_accuracy: 0.7610\n",
      "Epoch 48/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.2109 - accuracy: 0.9365\n",
      "Epoch 00048: val_loss did not improve from 0.87949\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.80976\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 0.2109 - accuracy: 0.9365 - val_loss: 1.7295 - val_accuracy: 0.7707\n",
      "Epoch 49/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.2289 - accuracy: 0.9425\n",
      "Epoch 00049: val_loss did not improve from 0.87949\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.80976\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 0.2289 - accuracy: 0.9425 - val_loss: 3.5849 - val_accuracy: 0.5415\n",
      "Epoch 50/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.3038 - accuracy: 0.9137\n",
      "Epoch 00050: val_loss did not improve from 0.87949\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.80976\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 0.3038 - accuracy: 0.9137 - val_loss: 7.1079 - val_accuracy: 0.3463\n",
      "Epoch 51/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.2602 - accuracy: 0.9311\n",
      "Epoch 00051: val_loss did not improve from 0.87949\n",
      "\n",
      "Epoch 00051: val_accuracy did not improve from 0.80976\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 0.2602 - accuracy: 0.9311 - val_loss: 1.2871 - val_accuracy: 0.7512\n",
      "Epoch 52/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.2497 - accuracy: 0.9387\n",
      "Epoch 00052: val_loss did not improve from 0.87949\n",
      "\n",
      "Epoch 00052: val_accuracy did not improve from 0.80976\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 0.2497 - accuracy: 0.9387 - val_loss: 3.2246 - val_accuracy: 0.5854\n",
      "Epoch 53/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.2248 - accuracy: 0.9327\n",
      "Epoch 00053: val_loss did not improve from 0.87949\n",
      "\n",
      "Epoch 00053: val_accuracy did not improve from 0.80976\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 0.2248 - accuracy: 0.9327 - val_loss: 1.6289 - val_accuracy: 0.6976\n",
      "Epoch 54/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1388 - accuracy: 0.9560\n",
      "Epoch 00054: val_loss did not improve from 0.87949\n",
      "\n",
      "Epoch 00054: val_accuracy did not improve from 0.80976\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 0.1388 - accuracy: 0.9560 - val_loss: 1.0211 - val_accuracy: 0.7951\n",
      "Epoch 55/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0966 - accuracy: 0.9674\n",
      "Epoch 00055: val_loss did not improve from 0.87949\n",
      "\n",
      "Epoch 00055: val_accuracy did not improve from 0.80976\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 0.0966 - accuracy: 0.9674 - val_loss: 1.5287 - val_accuracy: 0.7902\n",
      "Epoch 56/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1297 - accuracy: 0.9647\n",
      "Epoch 00056: val_loss did not improve from 0.87949\n",
      "\n",
      "Epoch 00056: val_accuracy did not improve from 0.80976\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 0.1297 - accuracy: 0.9647 - val_loss: 1.6699 - val_accuracy: 0.7659\n",
      "Epoch 57/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1089 - accuracy: 0.9685\n",
      "Epoch 00057: val_loss did not improve from 0.87949\n",
      "\n",
      "Epoch 00057: val_accuracy did not improve from 0.80976\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 0.1089 - accuracy: 0.9685 - val_loss: 1.4142 - val_accuracy: 0.7756\n",
      "Epoch 58/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0898 - accuracy: 0.9734\n",
      "Epoch 00058: val_loss did not improve from 0.87949\n",
      "\n",
      "Epoch 00058: val_accuracy did not improve from 0.80976\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 0.0898 - accuracy: 0.9734 - val_loss: 2.0150 - val_accuracy: 0.7122\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1623 - accuracy: 0.9512\n",
      "Epoch 00059: val_loss did not improve from 0.87949\n",
      "\n",
      "Epoch 00059: val_accuracy did not improve from 0.80976\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 0.1623 - accuracy: 0.9512 - val_loss: 2.0687 - val_accuracy: 0.7073\n",
      "Epoch 60/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1364 - accuracy: 0.9582\n",
      "Epoch 00060: val_loss did not improve from 0.87949\n",
      "\n",
      "Epoch 00060: val_accuracy did not improve from 0.80976\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 0.1364 - accuracy: 0.9582 - val_loss: 1.8640 - val_accuracy: 0.7805\n",
      "Epoch 61/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.2086 - accuracy: 0.9468\n",
      "Epoch 00061: val_loss did not improve from 0.87949\n",
      "\n",
      "Epoch 00061: val_accuracy improved from 0.80976 to 0.81951, saving model to ./home_models_0205\\02_04_AI_val_accuracy_index_2.h5\n",
      "58/58 [==============================] - 32s 549ms/step - loss: 0.2086 - accuracy: 0.9468 - val_loss: 1.0866 - val_accuracy: 0.8195\n",
      "Epoch 62/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.4848 - accuracy: 0.9002\n",
      "Epoch 00062: val_loss did not improve from 0.87949\n",
      "\n",
      "Epoch 00062: val_accuracy did not improve from 0.81951\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 0.4848 - accuracy: 0.9002 - val_loss: 2.2192 - val_accuracy: 0.6976\n",
      "Epoch 63/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.4750 - accuracy: 0.9050\n",
      "Epoch 00063: val_loss did not improve from 0.87949\n",
      "\n",
      "Epoch 00063: val_accuracy did not improve from 0.81951\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 0.4750 - accuracy: 0.9050 - val_loss: 3.3156 - val_accuracy: 0.6488\n",
      "Epoch 64/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.3007 - accuracy: 0.9338\n",
      "Epoch 00064: val_loss did not improve from 0.87949\n",
      "\n",
      "Epoch 00064: val_accuracy did not improve from 0.81951\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 0.3007 - accuracy: 0.9338 - val_loss: 3.1737 - val_accuracy: 0.6634\n",
      "Epoch 65/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1614 - accuracy: 0.9571\n",
      "Epoch 00065: val_loss did not improve from 0.87949\n",
      "\n",
      "Epoch 00065: val_accuracy did not improve from 0.81951\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 0.1614 - accuracy: 0.9571 - val_loss: 1.1337 - val_accuracy: 0.8195\n",
      "Epoch 66/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1405 - accuracy: 0.9609\n",
      "Epoch 00066: val_loss did not improve from 0.87949\n",
      "\n",
      "Epoch 00066: val_accuracy did not improve from 0.81951\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 0.1405 - accuracy: 0.9609 - val_loss: 2.1443 - val_accuracy: 0.7073\n",
      "Epoch 67/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1015 - accuracy: 0.9734\n",
      "Epoch 00067: val_loss did not improve from 0.87949\n",
      "\n",
      "Epoch 00067: val_accuracy did not improve from 0.81951\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 0.1015 - accuracy: 0.9734 - val_loss: 1.2595 - val_accuracy: 0.7902\n",
      "Epoch 68/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0937 - accuracy: 0.9756\n",
      "Epoch 00068: val_loss did not improve from 0.87949\n",
      "\n",
      "Epoch 00068: val_accuracy improved from 0.81951 to 0.84878, saving model to ./home_models_0205\\02_04_AI_val_accuracy_index_2.h5\n",
      "58/58 [==============================] - 32s 548ms/step - loss: 0.0937 - accuracy: 0.9756 - val_loss: 1.2208 - val_accuracy: 0.8488\n",
      "Epoch 69/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0789 - accuracy: 0.9794\n",
      "Epoch 00069: val_loss did not improve from 0.87949\n",
      "\n",
      "Epoch 00069: val_accuracy did not improve from 0.84878\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 0.0789 - accuracy: 0.9794 - val_loss: 1.3017 - val_accuracy: 0.8341\n",
      "Epoch 70/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0457 - accuracy: 0.9870\n",
      "Epoch 00070: val_loss did not improve from 0.87949\n",
      "\n",
      "Epoch 00070: val_accuracy improved from 0.84878 to 0.85366, saving model to ./home_models_0205\\02_04_AI_val_accuracy_index_2.h5\n",
      "58/58 [==============================] - 32s 549ms/step - loss: 0.0457 - accuracy: 0.9870 - val_loss: 1.0812 - val_accuracy: 0.8537\n",
      "Epoch 71/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0418 - accuracy: 0.9886\n",
      "Epoch 00071: val_loss did not improve from 0.87949\n",
      "\n",
      "Epoch 00071: val_accuracy did not improve from 0.85366\n",
      "58/58 [==============================] - 17s 294ms/step - loss: 0.0418 - accuracy: 0.9886 - val_loss: 1.5220 - val_accuracy: 0.7902\n",
      "Epoch 72/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0216 - accuracy: 0.9935\n",
      "Epoch 00072: val_loss did not improve from 0.87949\n",
      "\n",
      "Epoch 00072: val_accuracy did not improve from 0.85366\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 0.0216 - accuracy: 0.9935 - val_loss: 1.2738 - val_accuracy: 0.7951\n",
      "Epoch 73/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0271 - accuracy: 0.9924\n",
      "Epoch 00073: val_loss did not improve from 0.87949\n",
      "\n",
      "Epoch 00073: val_accuracy did not improve from 0.85366\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 0.0271 - accuracy: 0.9924 - val_loss: 1.4295 - val_accuracy: 0.8195\n",
      "Epoch 74/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0059 - accuracy: 0.9978\n",
      "Epoch 00074: val_loss did not improve from 0.87949\n",
      "\n",
      "Epoch 00074: val_accuracy did not improve from 0.85366\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 0.0059 - accuracy: 0.9978 - val_loss: 1.2985 - val_accuracy: 0.8146\n",
      "Epoch 75/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0051 - accuracy: 0.9995\n",
      "Epoch 00075: val_loss did not improve from 0.87949\n",
      "\n",
      "Epoch 00075: val_accuracy did not improve from 0.85366\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 0.0051 - accuracy: 0.9995 - val_loss: 1.2093 - val_accuracy: 0.8537\n",
      "Epoch 76/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 6.8291e-04 - accuracy: 1.0000\n",
      "Epoch 00076: val_loss did not improve from 0.87949\n",
      "\n",
      "Epoch 00076: val_accuracy did not improve from 0.85366\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 6.8291e-04 - accuracy: 1.0000 - val_loss: 1.2186 - val_accuracy: 0.8537\n",
      "Epoch 77/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 5.6598e-04 - accuracy: 1.0000\n",
      "Epoch 00077: val_loss did not improve from 0.87949\n",
      "\n",
      "Epoch 00077: val_accuracy did not improve from 0.85366\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 5.6598e-04 - accuracy: 1.0000 - val_loss: 1.1510 - val_accuracy: 0.8537\n",
      "Epoch 78/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 5.5486e-04 - accuracy: 1.0000\n",
      "Epoch 00078: val_loss did not improve from 0.87949\n",
      "\n",
      "Epoch 00078: val_accuracy did not improve from 0.85366\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 5.5486e-04 - accuracy: 1.0000 - val_loss: 1.1485 - val_accuracy: 0.8439\n",
      "Epoch 79/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 3.2544e-04 - accuracy: 1.0000\n",
      "Epoch 00079: val_loss did not improve from 0.87949\n",
      "\n",
      "Epoch 00079: val_accuracy did not improve from 0.85366\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 3.2544e-04 - accuracy: 1.0000 - val_loss: 1.1828 - val_accuracy: 0.8537\n",
      "Epoch 80/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 00080: val_loss did not improve from 0.87949\n",
      "\n",
      "Epoch 00080: val_accuracy did not improve from 0.85366\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.3134 - val_accuracy: 0.8390\n",
      "Epoch 81/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 1.1773e-04 - accuracy: 1.0000\n",
      "Epoch 00081: val_loss did not improve from 0.87949\n",
      "\n",
      "Epoch 00081: ReduceLROnPlateau reducing learning rate to 0.001500000013038516.\n",
      "\n",
      "Epoch 00081: val_accuracy did not improve from 0.85366\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 1.1773e-04 - accuracy: 1.0000 - val_loss: 1.3504 - val_accuracy: 0.8293\n",
      "Epoch 82/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 3.7172e-04 - accuracy: 1.0000\n",
      "Epoch 00082: val_loss did not improve from 0.87949\n",
      "\n",
      "Epoch 00082: val_accuracy did not improve from 0.85366\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 3.7172e-04 - accuracy: 1.0000 - val_loss: 1.2303 - val_accuracy: 0.8488\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 2.3764e-04 - accuracy: 1.0000\n",
      "Epoch 00083: val_loss did not improve from 0.87949\n",
      "\n",
      "Epoch 00083: val_accuracy did not improve from 0.85366\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 2.3764e-04 - accuracy: 1.0000 - val_loss: 1.2052 - val_accuracy: 0.8390\n",
      "Epoch 84/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 2.1764e-04 - accuracy: 1.0000\n",
      "Epoch 00084: val_loss did not improve from 0.87949\n",
      "\n",
      "Epoch 00084: val_accuracy did not improve from 0.85366\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 2.1764e-04 - accuracy: 1.0000 - val_loss: 1.1776 - val_accuracy: 0.8439\n",
      "Epoch 85/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 1.7499e-04 - accuracy: 1.0000\n",
      "Epoch 00085: val_loss did not improve from 0.87949\n",
      "\n",
      "Epoch 00085: val_accuracy improved from 0.85366 to 0.85854, saving model to ./home_models_0205\\02_04_AI_val_accuracy_index_2.h5\n",
      "58/58 [==============================] - 31s 543ms/step - loss: 1.7499e-04 - accuracy: 1.0000 - val_loss: 1.0748 - val_accuracy: 0.8585\n",
      "Epoch 86/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 8.4889e-05 - accuracy: 1.0000\n",
      "Epoch 00086: val_loss did not improve from 0.87949\n",
      "\n",
      "Epoch 00086: val_accuracy did not improve from 0.85854\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 8.4889e-05 - accuracy: 1.0000 - val_loss: 1.2219 - val_accuracy: 0.8488\n",
      "Epoch 87/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 2.2310e-04 - accuracy: 1.0000\n",
      "Epoch 00087: val_loss did not improve from 0.87949\n",
      "\n",
      "Epoch 00087: val_accuracy did not improve from 0.85854\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 2.2310e-04 - accuracy: 1.0000 - val_loss: 1.1938 - val_accuracy: 0.8488\n",
      "Epoch 88/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 1.0561e-04 - accuracy: 1.0000\n",
      "Epoch 00088: val_loss did not improve from 0.87949\n",
      "\n",
      "Epoch 00088: val_accuracy did not improve from 0.85854\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 1.0561e-04 - accuracy: 1.0000 - val_loss: 1.0433 - val_accuracy: 0.8585\n",
      "Epoch 89/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 9.1935e-05 - accuracy: 1.0000\n",
      "Epoch 00089: val_loss did not improve from 0.87949\n",
      "\n",
      "Epoch 00089: val_accuracy did not improve from 0.85854\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 9.1935e-05 - accuracy: 1.0000 - val_loss: 1.1925 - val_accuracy: 0.8390\n",
      "Epoch 90/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 4.4437e-05 - accuracy: 1.0000\n",
      "Epoch 00090: val_loss did not improve from 0.87949\n",
      "\n",
      "Epoch 00090: val_accuracy did not improve from 0.85854\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 4.4437e-05 - accuracy: 1.0000 - val_loss: 1.1676 - val_accuracy: 0.8390\n",
      "Epoch 91/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 4.8607e-05 - accuracy: 1.0000\n",
      "Epoch 00091: val_loss did not improve from 0.87949\n",
      "\n",
      "Epoch 00091: val_accuracy did not improve from 0.85854\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 4.8607e-05 - accuracy: 1.0000 - val_loss: 1.2119 - val_accuracy: 0.8488\n",
      "Epoch 92/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 5.3553e-05 - accuracy: 1.0000\n",
      "Epoch 00092: val_loss did not improve from 0.87949\n",
      "\n",
      "Epoch 00092: val_accuracy did not improve from 0.85854\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 5.3553e-05 - accuracy: 1.0000 - val_loss: 1.0953 - val_accuracy: 0.8439\n",
      "Epoch 93/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 1.5488e-04 - accuracy: 1.0000\n",
      "Epoch 00093: val_loss did not improve from 0.87949\n",
      "\n",
      "Epoch 00093: val_accuracy did not improve from 0.85854\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 1.5488e-04 - accuracy: 1.0000 - val_loss: 1.2749 - val_accuracy: 0.8390\n",
      "Epoch 94/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 7.3241e-05 - accuracy: 1.0000\n",
      "Epoch 00094: val_loss did not improve from 0.87949\n",
      "\n",
      "Epoch 00094: val_accuracy did not improve from 0.85854\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 7.3241e-05 - accuracy: 1.0000 - val_loss: 1.2772 - val_accuracy: 0.8390\n",
      "Epoch 95/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 3.8995e-05 - accuracy: 1.0000\n",
      "Epoch 00095: val_loss did not improve from 0.87949\n",
      "\n",
      "Epoch 00095: val_accuracy did not improve from 0.85854\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 3.8995e-05 - accuracy: 1.0000 - val_loss: 1.2623 - val_accuracy: 0.8390\n",
      "Epoch 96/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 3.5064e-05 - accuracy: 1.0000\n",
      "Epoch 00096: val_loss did not improve from 0.87949\n",
      "\n",
      "Epoch 00096: val_accuracy did not improve from 0.85854\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 3.5064e-05 - accuracy: 1.0000 - val_loss: 1.1519 - val_accuracy: 0.8537\n",
      "Epoch 97/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 8.9632e-05 - accuracy: 1.0000\n",
      "Epoch 00097: val_loss did not improve from 0.87949\n",
      "\n",
      "Epoch 00097: val_accuracy improved from 0.85854 to 0.86341, saving model to ./home_models_0205\\02_04_AI_val_accuracy_index_2.h5\n",
      "58/58 [==============================] - 32s 546ms/step - loss: 8.9632e-05 - accuracy: 1.0000 - val_loss: 1.0878 - val_accuracy: 0.8634\n",
      "Epoch 98/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 3.9648e-05 - accuracy: 1.0000\n",
      "Epoch 00098: val_loss did not improve from 0.87949\n",
      "\n",
      "Epoch 00098: val_accuracy did not improve from 0.86341\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 3.9648e-05 - accuracy: 1.0000 - val_loss: 1.2476 - val_accuracy: 0.8390\n",
      "Epoch 99/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 7.9438e-05 - accuracy: 1.0000\n",
      "Epoch 00099: val_loss did not improve from 0.87949\n",
      "\n",
      "Epoch 00099: val_accuracy did not improve from 0.86341\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 7.9438e-05 - accuracy: 1.0000 - val_loss: 1.2089 - val_accuracy: 0.8634\n",
      "Epoch 100/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 3.5537e-05 - accuracy: 1.0000\n",
      "Epoch 00100: val_loss did not improve from 0.87949\n",
      "\n",
      "Epoch 00100: val_accuracy did not improve from 0.86341\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 3.5537e-05 - accuracy: 1.0000 - val_loss: 1.1266 - val_accuracy: 0.8537\n",
      "Epoch 101/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 2.0906e-05 - accuracy: 1.0000\n",
      "Epoch 00101: val_loss did not improve from 0.87949\n",
      "\n",
      "Epoch 00101: val_accuracy did not improve from 0.86341\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 2.0906e-05 - accuracy: 1.0000 - val_loss: 1.0515 - val_accuracy: 0.8585\n",
      "Epoch 102/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 6.3354e-05 - accuracy: 1.0000\n",
      "Epoch 00102: val_loss did not improve from 0.87949\n",
      "\n",
      "Epoch 00102: val_accuracy did not improve from 0.86341\n",
      "58/58 [==============================] - 17s 296ms/step - loss: 6.3354e-05 - accuracy: 1.0000 - val_loss: 1.1415 - val_accuracy: 0.8341\n",
      "Epoch 103/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 3.2221e-05 - accuracy: 1.0000\n",
      "Epoch 00103: val_loss did not improve from 0.87949\n",
      "\n",
      "Epoch 00103: val_accuracy did not improve from 0.86341\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 3.2221e-05 - accuracy: 1.0000 - val_loss: 1.2316 - val_accuracy: 0.8341\n",
      "Epoch 104/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 3.3731e-05 - accuracy: 1.0000\n",
      "Epoch 00104: val_loss did not improve from 0.87949\n",
      "\n",
      "Epoch 00104: val_accuracy did not improve from 0.86341\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 3.3731e-05 - accuracy: 1.0000 - val_loss: 1.1488 - val_accuracy: 0.8488\n",
      "Epoch 105/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 3.7410e-05 - accuracy: 1.0000\n",
      "Epoch 00105: val_loss did not improve from 0.87949\n",
      "\n",
      "Epoch 00105: val_accuracy did not improve from 0.86341\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 3.7410e-05 - accuracy: 1.0000 - val_loss: 1.3221 - val_accuracy: 0.8439\n",
      "Epoch 106/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 3.0603e-05 - accuracy: 1.0000\n",
      "Epoch 00106: val_loss did not improve from 0.87949\n",
      "\n",
      "Epoch 00106: val_accuracy did not improve from 0.86341\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 3.0603e-05 - accuracy: 1.0000 - val_loss: 1.2278 - val_accuracy: 0.8488\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 107/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 7.1213e-05 - accuracy: 1.0000\n",
      "Epoch 00107: val_loss did not improve from 0.87949\n",
      "\n",
      "Epoch 00107: val_accuracy did not improve from 0.86341\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 7.1213e-05 - accuracy: 1.0000 - val_loss: 1.1377 - val_accuracy: 0.8585\n",
      "Epoch 108/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 2.8914e-05 - accuracy: 1.0000\n",
      "Epoch 00108: val_loss did not improve from 0.87949\n",
      "\n",
      "Epoch 00108: val_accuracy did not improve from 0.86341\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 2.8914e-05 - accuracy: 1.0000 - val_loss: 1.2158 - val_accuracy: 0.8341\n",
      "Epoch 109/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 2.5837e-05 - accuracy: 1.0000\n",
      "Epoch 00109: val_loss did not improve from 0.87949\n",
      "\n",
      "Epoch 00109: val_accuracy did not improve from 0.86341\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 2.5837e-05 - accuracy: 1.0000 - val_loss: 1.1750 - val_accuracy: 0.8634\n",
      "Epoch 110/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 2.6514e-05 - accuracy: 1.0000\n",
      "Epoch 00110: val_loss did not improve from 0.87949\n",
      "\n",
      "Epoch 00110: val_accuracy did not improve from 0.86341\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 2.6514e-05 - accuracy: 1.0000 - val_loss: 1.3226 - val_accuracy: 0.8439\n",
      "Epoch 111/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 3.8043e-05 - accuracy: 1.0000\n",
      "Epoch 00111: val_loss did not improve from 0.87949\n",
      "\n",
      "Epoch 00111: val_accuracy did not improve from 0.86341\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 3.8043e-05 - accuracy: 1.0000 - val_loss: 1.3107 - val_accuracy: 0.8390\n",
      "Epoch 112/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 1.1325e-04 - accuracy: 1.0000\n",
      "Epoch 00112: val_loss did not improve from 0.87949\n",
      "\n",
      "Epoch 00112: val_accuracy did not improve from 0.86341\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 1.1325e-04 - accuracy: 1.0000 - val_loss: 1.2105 - val_accuracy: 0.8537\n",
      "Epoch 113/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 8.0773e-05 - accuracy: 1.0000\n",
      "Epoch 00113: val_loss did not improve from 0.87949\n",
      "\n",
      "Epoch 00113: val_accuracy did not improve from 0.86341\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 8.0773e-05 - accuracy: 1.0000 - val_loss: 1.3668 - val_accuracy: 0.8488\n",
      "Epoch 114/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 6.0108e-05 - accuracy: 1.0000\n",
      "Epoch 00114: val_loss did not improve from 0.87949\n",
      "\n",
      "Epoch 00114: val_accuracy did not improve from 0.86341\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 6.0108e-05 - accuracy: 1.0000 - val_loss: 1.3207 - val_accuracy: 0.8634\n",
      "Epoch 115/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 3.2676e-05 - accuracy: 1.0000\n",
      "Epoch 00115: val_loss did not improve from 0.87949\n",
      "\n",
      "Epoch 00115: val_accuracy did not improve from 0.86341\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 3.2676e-05 - accuracy: 1.0000 - val_loss: 1.2165 - val_accuracy: 0.8439\n",
      "Epoch 116/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 3.0671e-05 - accuracy: 1.0000\n",
      "Epoch 00116: val_loss did not improve from 0.87949\n",
      "\n",
      "Epoch 00116: val_accuracy did not improve from 0.86341\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 3.0671e-05 - accuracy: 1.0000 - val_loss: 1.2580 - val_accuracy: 0.8341\n",
      "Epoch 117/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 1.7880e-05 - accuracy: 1.0000\n",
      "Epoch 00117: val_loss did not improve from 0.87949\n",
      "\n",
      "Epoch 00117: val_accuracy did not improve from 0.86341\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 1.7880e-05 - accuracy: 1.0000 - val_loss: 1.2538 - val_accuracy: 0.8439\n",
      "Epoch 118/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 2.0819e-05 - accuracy: 1.0000\n",
      "Epoch 00118: val_loss did not improve from 0.87949\n",
      "\n",
      "Epoch 00118: val_accuracy did not improve from 0.86341\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 2.0819e-05 - accuracy: 1.0000 - val_loss: 1.1493 - val_accuracy: 0.8537\n",
      "Epoch 119/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 1.7290e-05 - accuracy: 1.0000\n",
      "Epoch 00119: val_loss did not improve from 0.87949\n",
      "\n",
      "Epoch 00119: val_accuracy did not improve from 0.86341\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 1.7290e-05 - accuracy: 1.0000 - val_loss: 1.3433 - val_accuracy: 0.8537\n",
      "Epoch 120/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 3.4315e-05 - accuracy: 1.0000\n",
      "Epoch 00120: val_loss did not improve from 0.87949\n",
      "\n",
      "Epoch 00120: val_accuracy did not improve from 0.86341\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 3.4315e-05 - accuracy: 1.0000 - val_loss: 1.1906 - val_accuracy: 0.8488\n",
      "Epoch 121/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 2.0821e-05 - accuracy: 1.0000\n",
      "Epoch 00121: val_loss did not improve from 0.87949\n",
      "\n",
      "Epoch 00121: ReduceLROnPlateau reducing learning rate to 0.000750000006519258.\n",
      "\n",
      "Epoch 00121: val_accuracy did not improve from 0.86341\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 2.0821e-05 - accuracy: 1.0000 - val_loss: 1.3190 - val_accuracy: 0.8634\n",
      "Epoch 122/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 1.6087e-05 - accuracy: 1.0000\n",
      "Epoch 00122: val_loss did not improve from 0.87949\n",
      "\n",
      "Epoch 00122: val_accuracy did not improve from 0.86341\n",
      "58/58 [==============================] - 17s 296ms/step - loss: 1.6087e-05 - accuracy: 1.0000 - val_loss: 1.2985 - val_accuracy: 0.8488\n",
      "Epoch 123/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 1.8458e-05 - accuracy: 1.0000\n",
      "Epoch 00123: val_loss did not improve from 0.87949\n",
      "\n",
      "Epoch 00123: val_accuracy did not improve from 0.86341\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 1.8458e-05 - accuracy: 1.0000 - val_loss: 1.2312 - val_accuracy: 0.8585\n",
      "Epoch 124/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 2.2280e-05 - accuracy: 1.0000\n",
      "Epoch 00124: val_loss did not improve from 0.87949\n",
      "\n",
      "Epoch 00124: val_accuracy did not improve from 0.86341\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 2.2280e-05 - accuracy: 1.0000 - val_loss: 1.0084 - val_accuracy: 0.8585\n",
      "Epoch 125/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 2.5084e-05 - accuracy: 1.0000\n",
      "Epoch 00125: val_loss did not improve from 0.87949\n",
      "\n",
      "Epoch 00125: val_accuracy did not improve from 0.86341\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 2.5084e-05 - accuracy: 1.0000 - val_loss: 1.2709 - val_accuracy: 0.8634\n",
      "Epoch 126/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 1.7383e-05 - accuracy: 1.0000\n",
      "Epoch 00126: val_loss did not improve from 0.87949\n",
      "\n",
      "Epoch 00126: val_accuracy did not improve from 0.86341\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 1.7383e-05 - accuracy: 1.0000 - val_loss: 1.2225 - val_accuracy: 0.8537\n",
      "Epoch 127/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 8.9014e-05 - accuracy: 1.0000\n",
      "Epoch 00127: val_loss did not improve from 0.87949\n",
      "\n",
      "Epoch 00127: val_accuracy did not improve from 0.86341\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 8.9014e-05 - accuracy: 1.0000 - val_loss: 0.9718 - val_accuracy: 0.8537\n",
      "Epoch 128/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 9.7745e-05 - accuracy: 1.0000\n",
      "Epoch 00128: val_loss did not improve from 0.87949\n",
      "\n",
      "Epoch 00128: val_accuracy did not improve from 0.86341\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 9.7745e-05 - accuracy: 1.0000 - val_loss: 1.2998 - val_accuracy: 0.8488\n",
      "Epoch 129/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 1.9757e-05 - accuracy: 1.0000\n",
      "Epoch 00129: val_loss did not improve from 0.87949\n",
      "\n",
      "Epoch 00129: val_accuracy did not improve from 0.86341\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 1.9757e-05 - accuracy: 1.0000 - val_loss: 1.1458 - val_accuracy: 0.8488\n",
      "Epoch 130/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 1.8441e-05 - accuracy: 1.0000\n",
      "Epoch 00130: val_loss did not improve from 0.87949\n",
      "\n",
      "Epoch 00130: val_accuracy did not improve from 0.86341\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 1.8441e-05 - accuracy: 1.0000 - val_loss: 1.0941 - val_accuracy: 0.8488\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 131/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 2.3324e-05 - accuracy: 1.0000\n",
      "Epoch 00131: val_loss did not improve from 0.87949\n",
      "\n",
      "Epoch 00131: val_accuracy did not improve from 0.86341\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 2.3324e-05 - accuracy: 1.0000 - val_loss: 1.2084 - val_accuracy: 0.8537\n",
      "Epoch 132/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 1.0268e-05 - accuracy: 1.0000\n",
      "Epoch 00132: val_loss did not improve from 0.87949\n",
      "\n",
      "Epoch 00132: val_accuracy did not improve from 0.86341\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 1.0268e-05 - accuracy: 1.0000 - val_loss: 1.3143 - val_accuracy: 0.8439\n",
      "Epoch 133/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 2.1133e-05 - accuracy: 1.0000\n",
      "Epoch 00133: val_loss did not improve from 0.87949\n",
      "\n",
      "Epoch 00133: val_accuracy did not improve from 0.86341\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 2.1133e-05 - accuracy: 1.0000 - val_loss: 1.3551 - val_accuracy: 0.8537\n",
      "Epoch 134/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 1.5631e-05 - accuracy: 1.0000\n",
      "Epoch 00134: val_loss did not improve from 0.87949\n",
      "\n",
      "Epoch 00134: val_accuracy did not improve from 0.86341\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 1.5631e-05 - accuracy: 1.0000 - val_loss: 1.2924 - val_accuracy: 0.8439\n",
      "Epoch 135/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 2.0784e-05 - accuracy: 1.0000\n",
      "Epoch 00135: val_loss did not improve from 0.87949\n",
      "\n",
      "Epoch 00135: val_accuracy did not improve from 0.86341\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 2.0784e-05 - accuracy: 1.0000 - val_loss: 1.0878 - val_accuracy: 0.8439\n",
      "Epoch 136/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 1.8129e-05 - accuracy: 1.0000\n",
      "Epoch 00136: val_loss did not improve from 0.87949\n",
      "\n",
      "Epoch 00136: val_accuracy did not improve from 0.86341\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 1.8129e-05 - accuracy: 1.0000 - val_loss: 1.2492 - val_accuracy: 0.8439\n",
      "Epoch 137/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 2.1311e-05 - accuracy: 1.0000\n",
      "Epoch 00137: val_loss did not improve from 0.87949\n",
      "\n",
      "Epoch 00137: val_accuracy did not improve from 0.86341\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 2.1311e-05 - accuracy: 1.0000 - val_loss: 1.2535 - val_accuracy: 0.8634\n",
      "Epoch 138/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 1.6012e-05 - accuracy: 1.0000\n",
      "Epoch 00138: val_loss did not improve from 0.87949\n",
      "\n",
      "Epoch 00138: val_accuracy did not improve from 0.86341\n",
      "58/58 [==============================] - 17s 296ms/step - loss: 1.6012e-05 - accuracy: 1.0000 - val_loss: 1.2027 - val_accuracy: 0.8537\n",
      "Epoch 139/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 1.3268e-05 - accuracy: 1.0000\n",
      "Epoch 00139: val_loss did not improve from 0.87949\n",
      "\n",
      "Epoch 00139: val_accuracy did not improve from 0.86341\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 1.3268e-05 - accuracy: 1.0000 - val_loss: 1.3169 - val_accuracy: 0.8537\n",
      "Epoch 140/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 1.8119e-05 - accuracy: 1.0000\n",
      "Epoch 00140: val_loss did not improve from 0.87949\n",
      "\n",
      "Epoch 00140: val_accuracy did not improve from 0.86341\n",
      "58/58 [==============================] - 17s 298ms/step - loss: 1.8119e-05 - accuracy: 1.0000 - val_loss: 1.2000 - val_accuracy: 0.8634\n",
      "Epoch 141/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 2.1562e-05 - accuracy: 1.0000\n",
      "Epoch 00141: val_loss did not improve from 0.87949\n",
      "\n",
      "Epoch 00141: val_accuracy did not improve from 0.86341\n",
      "58/58 [==============================] - 17s 297ms/step - loss: 2.1562e-05 - accuracy: 1.0000 - val_loss: 1.1451 - val_accuracy: 0.8439\n",
      "2  번째 학습을 완료했습니다.\n",
      "Epoch 1/2000\n",
      " 2/58 [>.............................] - ETA: 8s - loss: 41.5038 - accuracy: 0.1094WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0995s vs `on_train_batch_end` time: 0.1875s). Check your callbacks.\n",
      "58/58 [==============================] - ETA: 0s - loss: 15.5272 - accuracy: 0.0982\n",
      "Epoch 00001: val_loss improved from inf to 3601.11011, saving model to ./home_models_0205\\02_04_AI_val_loss_index_3.h5\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.10244, saving model to ./home_models_0205\\02_04_AI_val_accuracy_index_3.h5\n",
      "58/58 [==============================] - 21s 368ms/step - loss: 15.5272 - accuracy: 0.0982 - val_loss: 3601.1101 - val_accuracy: 0.1024\n",
      "Epoch 2/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 2.4489 - accuracy: 0.1335\n",
      "Epoch 00002: val_loss improved from 3601.11011 to 8.01696, saving model to ./home_models_0205\\02_04_AI_val_loss_index_3.h5\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.10244 to 0.11707, saving model to ./home_models_0205\\02_04_AI_val_accuracy_index_3.h5\n",
      "58/58 [==============================] - 21s 363ms/step - loss: 2.4489 - accuracy: 0.1335 - val_loss: 8.0170 - val_accuracy: 0.1171\n",
      "Epoch 3/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 2.4072 - accuracy: 0.1335\n",
      "Epoch 00003: val_loss improved from 8.01696 to 6.90876, saving model to ./home_models_0205\\02_04_AI_val_loss_index_3.h5\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.11707\n",
      "58/58 [==============================] - 19s 331ms/step - loss: 2.4072 - accuracy: 0.1335 - val_loss: 6.9088 - val_accuracy: 0.0732\n",
      "Epoch 4/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 2.2402 - accuracy: 0.1910\n",
      "Epoch 00004: val_loss improved from 6.90876 to 3.14379, saving model to ./home_models_0205\\02_04_AI_val_loss_index_3.h5\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.11707\n",
      "58/58 [==============================] - 19s 331ms/step - loss: 2.2402 - accuracy: 0.1910 - val_loss: 3.1438 - val_accuracy: 0.0732\n",
      "Epoch 5/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 2.1721 - accuracy: 0.2420\n",
      "Epoch 00005: val_loss improved from 3.14379 to 2.75936, saving model to ./home_models_0205\\02_04_AI_val_loss_index_3.h5\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.11707\n",
      "58/58 [==============================] - 20s 341ms/step - loss: 2.1721 - accuracy: 0.2420 - val_loss: 2.7594 - val_accuracy: 0.1171\n",
      "Epoch 6/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 1.9677 - accuracy: 0.3228\n",
      "Epoch 00006: val_loss did not improve from 2.75936\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.11707\n",
      "58/58 [==============================] - 17s 299ms/step - loss: 1.9677 - accuracy: 0.3228 - val_loss: 3.9080 - val_accuracy: 0.1024\n",
      "Epoch 7/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 1.6366 - accuracy: 0.4292\n",
      "Epoch 00007: val_loss did not improve from 2.75936\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.11707 to 0.12195, saving model to ./home_models_0205\\02_04_AI_val_accuracy_index_3.h5\n",
      "58/58 [==============================] - 32s 554ms/step - loss: 1.6366 - accuracy: 0.4292 - val_loss: 2.9832 - val_accuracy: 0.1220\n",
      "Epoch 8/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 1.4564 - accuracy: 0.4976\n",
      "Epoch 00008: val_loss did not improve from 2.75936\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.12195\n",
      "58/58 [==============================] - 17s 296ms/step - loss: 1.4564 - accuracy: 0.4976 - val_loss: 33.4524 - val_accuracy: 0.1073\n",
      "Epoch 9/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 1.1063 - accuracy: 0.6240\n",
      "Epoch 00009: val_loss improved from 2.75936 to 1.82792, saving model to ./home_models_0205\\02_04_AI_val_loss_index_3.h5\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.12195 to 0.39512, saving model to ./home_models_0205\\02_04_AI_val_accuracy_index_3.h5\n",
      "58/58 [==============================] - 47s 814ms/step - loss: 1.1063 - accuracy: 0.6240 - val_loss: 1.8279 - val_accuracy: 0.3951\n",
      "Epoch 10/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 1.0578 - accuracy: 0.6435\n",
      "Epoch 00010: val_loss did not improve from 1.82792\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.39512\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 1.0578 - accuracy: 0.6435 - val_loss: 3.2672 - val_accuracy: 0.1366\n",
      "Epoch 11/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58/58 [==============================] - ETA: 0s - loss: 0.9868 - accuracy: 0.6658\n",
      "Epoch 00011: val_loss improved from 1.82792 to 1.20322, saving model to ./home_models_0205\\02_04_AI_val_loss_index_3.h5\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.39512 to 0.60488, saving model to ./home_models_0205\\02_04_AI_val_accuracy_index_3.h5\n",
      "58/58 [==============================] - 48s 825ms/step - loss: 0.9868 - accuracy: 0.6658 - val_loss: 1.2032 - val_accuracy: 0.6049\n",
      "Epoch 12/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.8054 - accuracy: 0.7206\n",
      "Epoch 00012: val_loss did not improve from 1.20322\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.60488\n",
      "58/58 [==============================] - 17s 294ms/step - loss: 0.8054 - accuracy: 0.7206 - val_loss: 1.7879 - val_accuracy: 0.4829\n",
      "Epoch 13/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.6847 - accuracy: 0.7678\n",
      "Epoch 00013: val_loss improved from 1.20322 to 1.16824, saving model to ./home_models_0205\\02_04_AI_val_loss_index_3.h5\n",
      "\n",
      "Epoch 00013: val_accuracy improved from 0.60488 to 0.64878, saving model to ./home_models_0205\\02_04_AI_val_accuracy_index_3.h5\n",
      "58/58 [==============================] - 48s 831ms/step - loss: 0.6847 - accuracy: 0.7678 - val_loss: 1.1682 - val_accuracy: 0.6488\n",
      "Epoch 14/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.7468 - accuracy: 0.7569\n",
      "Epoch 00014: val_loss did not improve from 1.16824\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.64878\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 0.7468 - accuracy: 0.7569 - val_loss: 2.0857 - val_accuracy: 0.5268\n",
      "Epoch 15/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.5931 - accuracy: 0.8068\n",
      "Epoch 00015: val_loss did not improve from 1.16824\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.64878\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 0.5931 - accuracy: 0.8068 - val_loss: 2.4214 - val_accuracy: 0.4293\n",
      "Epoch 16/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.5815 - accuracy: 0.7949\n",
      "Epoch 00016: val_loss improved from 1.16824 to 1.11374, saving model to ./home_models_0205\\02_04_AI_val_loss_index_3.h5\n",
      "\n",
      "Epoch 00016: val_accuracy improved from 0.64878 to 0.67317, saving model to ./home_models_0205\\02_04_AI_val_accuracy_index_3.h5\n",
      "58/58 [==============================] - 48s 829ms/step - loss: 0.5815 - accuracy: 0.7949 - val_loss: 1.1137 - val_accuracy: 0.6732\n",
      "Epoch 17/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.4123 - accuracy: 0.8546\n",
      "Epoch 00017: val_loss improved from 1.11374 to 1.09195, saving model to ./home_models_0205\\02_04_AI_val_loss_index_3.h5\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.67317\n",
      "58/58 [==============================] - 19s 330ms/step - loss: 0.4123 - accuracy: 0.8546 - val_loss: 1.0920 - val_accuracy: 0.6683\n",
      "Epoch 18/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.3959 - accuracy: 0.8551\n",
      "Epoch 00018: val_loss improved from 1.09195 to 0.69261, saving model to ./home_models_0205\\02_04_AI_val_loss_index_3.h5\n",
      "\n",
      "Epoch 00018: val_accuracy improved from 0.67317 to 0.76098, saving model to ./home_models_0205\\02_04_AI_val_accuracy_index_3.h5\n",
      "58/58 [==============================] - 34s 591ms/step - loss: 0.3959 - accuracy: 0.8551 - val_loss: 0.6926 - val_accuracy: 0.7610\n",
      "Epoch 19/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.3978 - accuracy: 0.8649\n",
      "Epoch 00019: val_loss did not improve from 0.69261\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.76098\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 0.3978 - accuracy: 0.8649 - val_loss: 1.2065 - val_accuracy: 0.6683\n",
      "Epoch 20/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.3231 - accuracy: 0.8899\n",
      "Epoch 00020: val_loss did not improve from 0.69261\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.76098\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 0.3231 - accuracy: 0.8899 - val_loss: 0.8582 - val_accuracy: 0.7220\n",
      "Epoch 21/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.3259 - accuracy: 0.8909\n",
      "Epoch 00021: val_loss did not improve from 0.69261\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.76098\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 0.3259 - accuracy: 0.8909 - val_loss: 1.6495 - val_accuracy: 0.5756\n",
      "Epoch 22/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.2791 - accuracy: 0.9045\n",
      "Epoch 00022: val_loss did not improve from 0.69261\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.76098\n",
      "58/58 [==============================] - 17s 296ms/step - loss: 0.2791 - accuracy: 0.9045 - val_loss: 0.9617 - val_accuracy: 0.7024\n",
      "Epoch 23/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.2916 - accuracy: 0.8958\n",
      "Epoch 00023: val_loss did not improve from 0.69261\n",
      "\n",
      "Epoch 00023: val_accuracy improved from 0.76098 to 0.77073, saving model to ./home_models_0205\\02_04_AI_val_accuracy_index_3.h5\n",
      "58/58 [==============================] - 32s 546ms/step - loss: 0.2916 - accuracy: 0.8958 - val_loss: 0.8743 - val_accuracy: 0.7707\n",
      "Epoch 24/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.2310 - accuracy: 0.9186\n",
      "Epoch 00024: val_loss did not improve from 0.69261\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.77073\n",
      "58/58 [==============================] - 17s 295ms/step - loss: 0.2310 - accuracy: 0.9186 - val_loss: 1.2910 - val_accuracy: 0.6585\n",
      "Epoch 25/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.3099 - accuracy: 0.8920\n",
      "Epoch 00025: val_loss did not improve from 0.69261\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.77073\n",
      "58/58 [==============================] - 17s 296ms/step - loss: 0.3099 - accuracy: 0.8920 - val_loss: 2.2002 - val_accuracy: 0.5415\n",
      "Epoch 26/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.2863 - accuracy: 0.9126\n",
      "Epoch 00026: val_loss did not improve from 0.69261\n",
      "\n",
      "Epoch 00026: val_accuracy improved from 0.77073 to 0.79024, saving model to ./home_models_0205\\02_04_AI_val_accuracy_index_3.h5\n",
      "58/58 [==============================] - 32s 548ms/step - loss: 0.2863 - accuracy: 0.9126 - val_loss: 0.7242 - val_accuracy: 0.7902\n",
      "Epoch 27/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1705 - accuracy: 0.9387\n",
      "Epoch 00027: val_loss did not improve from 0.69261\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.79024\n",
      "58/58 [==============================] - 17s 296ms/step - loss: 0.1705 - accuracy: 0.9387 - val_loss: 1.2059 - val_accuracy: 0.6488\n",
      "Epoch 28/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.2441 - accuracy: 0.9170\n",
      "Epoch 00028: val_loss did not improve from 0.69261\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.79024\n",
      "58/58 [==============================] - 17s 296ms/step - loss: 0.2441 - accuracy: 0.9170 - val_loss: 0.9079 - val_accuracy: 0.7659\n",
      "Epoch 29/2000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1703 - accuracy: 0.9403"
     ]
    }
   ],
   "source": [
    "index=1\n",
    "result = 0\n",
    "for train_index,val_index in kfold.split(x,y):\n",
    "    optimizer = Adam(lr=0.003,epsilon=None)\n",
    "    modelpath = './home_models_0205/02_04_AI_val_loss_index_{}.h5'.format(index)\n",
    "    modelpath2 = './home_models_0205/02_04_AI_val_accuracy_index_{}.h5'.format(index)\n",
    "    cp = ModelCheckpoint(monitor = 'val_loss',filepath=modelpath,save_best_only=True,verbose=1)\n",
    "    cp2 = ModelCheckpoint(monitor = 'val_accuracy',filepath=modelpath2,save_best_only=True,verbose=1)\n",
    "\n",
    "\n",
    "    x_train = x[train_index]\n",
    "    x_val = x[val_index]\n",
    "    y_train = y[train_index]\n",
    "    y_val = y[val_index]\n",
    "\n",
    "    onehot = OneHotEncoder()\n",
    "    y_train = onehot.fit_transform(y_train.reshape(-1,1)).toarray().astype('float32')\n",
    "    y_val = onehot.fit_transform(y_val.reshape(-1,1)).toarray().astype('float32')\n",
    "\n",
    "    train_generator = datagen.flow(x_train,y_train,batch_size=32)\n",
    "    val_generator = datagen.flow(x_val,y_val)\n",
    "    model = modeling()\n",
    "    model.compile(loss = 'categorical_crossentropy',optimizer = optimizer,metrics=['accuracy'])\n",
    "    model.fit_generator(train_generator,validation_data = val_generator,epochs=epochs,callbacks=[cp,es,reLR,cp2])\n",
    "\n",
    "    model = load_model(modelpath)\n",
    "    model2 = load_model(modelpath2)\n",
    "    df = pd.read_csv(\"test.csv\",index_col=[0])\n",
    "    x_test = df.values[:,1:].reshape(-1,28,28).astype('float32')/255.0\n",
    "    y_pred = model.predict(x_test)\n",
    "    y_pred2 = model2.predict(x_test)\n",
    "    y_pred = np.argmax(y_pred,axis=-1)\n",
    "    y_pred2 = np.argmax(y_pred2,axis=-1)\n",
    "    df_sub = pd.read_csv('submission.csv',index_col=0)\n",
    "    df_sub['digit'] = y_pred\n",
    "    df_sub.to_csv('./home_models_0205/loss_kfold_{}.csv'.format(index))\n",
    "    df_sub['digit'] = y_pred2\n",
    "    df_sub.to_csv('./home_models_0205/accuracy_kfold_{}.csv'.format(index))\n",
    "\n",
    "    print(index, \" 번째 학습을 완료했습니다.\")\n",
    "    index+=1\n",
    "\n",
    "\n",
    "    \n",
    "\"\"\"\n",
    "0.905\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "44FNCmNG-Mkd"
   },
   "outputs": [],
   "source": [
    "model = load_model('./AI_models/02_04_AI_val_loss_index_3.h5')\n",
    "#model = load_model('./models/02_03_imger_best_index_1.h5')\n",
    "df = pd.read_csv(\"test.csv\",index_col=[0])\n",
    "x_test = df.values[:,1:].reshape(-1,28,28).astype('float32')/255.0\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred = np.argmax(y_pred,axis=-1)\n",
    "df_sub = pd.read_csv('submission.csv',index_col=0)\n",
    "df_sub['digit'] = y_pred\n",
    "df_sub.to_csv('0204_f2.csv')\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_acc_loss_csv(index):\n",
    "    for i in range(1,index+1):\n",
    "        model1 = load_model('./home_models/02_04_AI_val_loss_index_{}.h5'.format(i))\n",
    "        model2 = load_model('./home_models/02_04_AI_val_accuracy_index_{}.h5'.format(i))\n",
    "        df = pd.read_csv(\"test.csv\",index_col=[0])\n",
    "        x_test = df.values[:,1:].reshape(-1,28,28).astype('float32')/255.0\n",
    "        y_pred = model.predict(x_test)\n",
    "        y_pred = np.argmax(y_pred,axis=-1)\n",
    "        y_pred2 = model2.predict(x_test)\n",
    "        y_pred2 = np.argmax(y_pred2,axis=-1)\n",
    "        df_sub = pd.read_csv('submission.csv',index_col=0)\n",
    "        df_sub['digit'] = y_pred\n",
    "        df_sub.to_csv('./home_models/val_loss_kfold_{}.csv'.format(i))\n",
    "        df_sub['digit'] = y_pred2\n",
    "        df_sub.to_csv('./home_models/val_accuracy_kfold_{}.csv'.format(i))\n",
    "make_acc_loss_csv(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_acc_loss_csv(index):\n",
    "    for i in range(1,index+1):\n",
    "        model1 = load_model('./AI_models/02_04_AI_val_loss_index_{}.h5'.format(i))\n",
    "        model2 = load_model('./AI_models/02_04_AI_val_accuracy_index_{}.h5'.format(i))\n",
    "        df = pd.read_csv(\"test.csv\",index_col=[0])\n",
    "        x_test = df.values[:,1:].reshape(-1,28,28).astype('float32')/255.0\n",
    "        y_pred = model.predict(x_test)\n",
    "        y_pred = np.argmax(y_pred,axis=-1)\n",
    "        y_pred2 = model2.predict(x_test)\n",
    "        y_pred2 = np.argmax(y_pred2,axis=-1)\n",
    "        df_sub = pd.read_csv('submission.csv',index_col=0)\n",
    "        df_sub['digit'] = y_pred\n",
    "        df_sub.to_csv('./AI_models/val_loss_kfold_{}.csv'.format(i))\n",
    "        df_sub['digit'] = y_pred2\n",
    "        df_sub.to_csv('./AI_models/val_accuracy_kfold_{}.csv'.format(i))\n",
    "make_acc_loss_csv(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensembles(index):\n",
    "    accuracy=[]\n",
    "    for i in range(1,index+1):\n",
    "        a = pd.read_csv(\"./home_models/val_accuracy_kfold_{}.csv\".format(i),index_col=0)\n",
    "        accuracy.append(a.values)\n",
    "    accuracy = np.concatenate(accuracy,axis=1)\n",
    "            \n",
    "    loss=[]\n",
    "    for i in range(1,index+1):\n",
    "        b = pd.read_csv(\"./home_models/val_loss_kfold_{}.csv\".format(i),index_col=0)\n",
    "        loss.append(b.values)        \n",
    "    loss = np.concatenate(loss,axis=1)\n",
    "    \n",
    "    accuracy_list=[]\n",
    "    for j in range(len(accuracy)):\n",
    "        count_list=[0,0,0,0,0,0,0,0,0,0]\n",
    "        k = list(accuracy[j])\n",
    "        for n in k:\n",
    "            count_list[n]+=1\n",
    "        accuracy_mode = count_list.index(max(count_list))\n",
    "        accuracy_list.append(accuracy_mode)\n",
    "    accuracy_list = np.array(accuracy_list).reshape(-1,1)\n",
    "    df = pd.read_csv(\"submission.csv\",index_col=0)\n",
    "    df['digit'] = accuracy_list\n",
    "    df.to_csv('./home_models/accuracy_ensembles.csv')\n",
    "    \n",
    "    loss_list=[]\n",
    "    for j in range(len(loss)):\n",
    "        count_list=[0,0,0,0,0,0,0,0,0,0]\n",
    "        k = list(loss[j])\n",
    "        for n in k:\n",
    "            count_list[n]+=1\n",
    "        loss_mode = count_list.index(max(count_list))\n",
    "        loss_list.append(loss_mode)\n",
    "    loss_list = np.array(loss_list).reshape(-1,1)\n",
    "    df = pd.read_csv(\"submission.csv\",index_col=0)\n",
    "    df['digit'] = accuracy_list\n",
    "    df.to_csv('./home_models/loss_ensembles.csv')\n",
    "    \n",
    "    \n",
    "        \n",
    "    \n",
    "    result = np.concatenate([accuracy,loss],axis=1)\n",
    "    mode_list=[]\n",
    "    for j in range(len(result)):\n",
    "        count_list=[0,0,0,0,0,0,0,0,0,0]\n",
    "        k = list(result[j])\n",
    "        for n in k:\n",
    "            count_list[n]+=1\n",
    "        mode = count_list.index(max(count_list))\n",
    "        mode_list.append(mode)\n",
    "    mode_list = np.array(mode_list).reshape(-1,1)\n",
    "    df = pd.read_csv(\"submission.csv\",index_col=0)\n",
    "    df['digit'] = mode_list\n",
    "    df.to_csv('./home_models/both_ensembles'+'.csv')\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensembles(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y5_Acvtq-Mkk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k7pmh6Ej-Mkk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modeling():\n",
    "    inputs = Input(shape=(28,28,1))\n",
    "    x = inputs\n",
    "    _x = Conv2D(128,3,padding='same')(x)\n",
    "    _x = BatchNormalization()(_x)\n",
    "    _x = Activation('relu')(_x)\n",
    "    _x = Conv2D(256,3,padding='same')(_x)\n",
    "    _x = BatchNormalization()(_x)\n",
    "    _x = Activation('relu')(_x)\n",
    "    _x = Conv2D(512,3,padding='same')(_x)\n",
    "    _x = BatchNormalization()(_x)\n",
    "    _x = Activation('relu')(_x)\n",
    "    _x = Conv2D(1024,3,padding='same')(_x)\n",
    "    _x = BatchNormalization()(_x)\n",
    "    _x = Activation('relu')(_x)\n",
    "    _x = Conv2D(128,3,padding='same')(_x)\n",
    "    _x = BatchNormalization()(_x)\n",
    "    _x = Activation('relu')(_x)\n",
    "    x = _x\n",
    "    _x = Conv2D(128,3,padding='same')(x)\n",
    "    _x = BatchNormalization()(_x)\n",
    "    _x = Activation('relu')(_x)\n",
    "    _x = Conv2D(256,3,padding='same')(_x)\n",
    "    _x = BatchNormalization()(_x)\n",
    "    _x = Activation('relu')(_x)\n",
    "    _x = Conv2D(512,3,padding='same')(_x)\n",
    "    _x = BatchNormalization()(_x)\n",
    "    _x = Activation('relu')(_x)\n",
    "    _x = Conv2D(1024,3,padding='same')(_x)\n",
    "    _x = BatchNormalization()(_x)\n",
    "    _x = Activation('relu')(_x)\n",
    "    _x = Conv2D(128,3,padding='same')(_x)\n",
    "    _x = BatchNormalization()(_x)\n",
    "    _x = Activation('relu')(_x)\n",
    "    x = x+_x\n",
    "    x = MaxPooling2D(2)(x)\n",
    "    _x = Conv2D(128,3,padding='same')(x)\n",
    "    _x = BatchNormalization()(_x)\n",
    "    _x = Activation('relu')(_x)\n",
    "    _x = Conv2D(256,3,padding='same')(_x)\n",
    "    _x = BatchNormalization()(_x)\n",
    "    _x = Activation('relu')(_x)\n",
    "    _x = Conv2D(512,3,padding='same')(x)\n",
    "    _x = BatchNormalization()(_x)\n",
    "    _x = Activation('relu')(_x)\n",
    "    _x = Conv2D(1024,3,padding='same')(_x)\n",
    "    _x = BatchNormalization()(_x)\n",
    "    _x = Activation('relu')(_x)\n",
    "    _x = Conv2D(128,3,padding='same')(_x)\n",
    "    _x = BatchNormalization()(_x)\n",
    "    _x = Activation('relu')(_x)\n",
    "    x = x+_x\n",
    "    x = MaxPooling2D(2)(x)\n",
    "    _x = Conv2D(128,3,padding='same')(x)\n",
    "    _x = BatchNormalization()(_x)\n",
    "    _x = Activation('relu')(_x)\n",
    "    _x = Conv2D(256,3,padding='same')(_x)\n",
    "    _x = BatchNormalization()(_x)\n",
    "    _x = Activation('relu')(_x)\n",
    "    _x = Conv2D(512,3,padding='same')(x)\n",
    "    _x = BatchNormalization()(_x)\n",
    "    _x = Activation('relu')(_x)\n",
    "    _x = Conv2D(128,3,padding='same')(_x)\n",
    "    _x = BatchNormalization()(_x)\n",
    "    _x = Activation('relu')(_x)\n",
    "    x = x+_x\n",
    "    x = MaxPooling2D(2)(x)\n",
    "    _x = Conv2D(512,3,padding='same')(x)\n",
    "    _x = BatchNormalization()(_x)\n",
    "    _x = Activation('relu')(_x)\n",
    "    _x = Conv2D(1024,3,padding='same')(_x)\n",
    "    _x = BatchNormalization()(_x)\n",
    "    _x = Activation('relu')(_x)\n",
    "    _x = Conv2D(128,3,padding='same')(_x)\n",
    "    _x = BatchNormalization()(_x)\n",
    "    _x = Activation('relu')(_x)\n",
    "    _x = Conv2D(128,3,padding='same')(_x)\n",
    "    _x = BatchNormalization()(_x)\n",
    "    _x = Activation('relu')(_x)\n",
    "    x = x+_x\n",
    "    x = MaxPooling2D(2)(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(2048)(x)\n",
    "    x = Dense(10,activation='softmax')(x)\n",
    "    outputs=x\n",
    "    model = Model(inputs=inputs,outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models, layers\n",
    "from keras import Input\n",
    "from keras.models import Model, load_model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers, initializers, regularizers, metrics\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.layers import BatchNormalization, Conv2D, Activation, Dense, GlobalAveragePooling2D, MaxPooling2D, ZeroPadding2D, Add\n",
    " \n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    " \n",
    " \n",
    " \n",
    " \n",
    " \n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    " \n",
    "train_dir = os.path.join('./dataset/1/images/train')\n",
    "val_dir = os.path.join('./dataset/1/images/val')\n",
    " \n",
    " \n",
    " \n",
    "train_generator = train_datagen.flow_from_directory(train_dir, batch_size=16, target_size=(224, 224), color_mode='rgb')\n",
    "val_generator = val_datagen.flow_from_directory(val_dir, batch_size=16, target_size=(224, 224), color_mode='rgb')\n",
    " \n",
    "# number of classes\n",
    "K = 4\n",
    "\n",
    "input_tensor = Input(shape=(224, 224, 3), dtype='float32', name='input')\n",
    " \n",
    "def conv1_layer(x):    \n",
    "    x = ZeroPadding2D(padding=(3, 3))(x)\n",
    "    x = Conv2D(64, (7, 7), strides=(2, 2))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = ZeroPadding2D(padding=(1,1))(x)\n",
    " \n",
    "    return x   \n",
    " \n",
    "    \n",
    "def conv2_layer(x):         \n",
    "    x = MaxPooling2D((3, 3), 2)(x)     \n",
    " \n",
    "    shortcut = x\n",
    " \n",
    "    for i in range(3):\n",
    "        if (i == 0):\n",
    "            x = Conv2D(64, (1, 1), strides=(1, 1), padding='valid')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)\n",
    "            \n",
    "            x = Conv2D(64, (3, 3), strides=(1, 1), padding='same')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)\n",
    " \n",
    "            x = Conv2D(256, (1, 1), strides=(1, 1), padding='valid')(x)\n",
    "            shortcut = Conv2D(256, (1, 1), strides=(1, 1), padding='valid')(shortcut)            \n",
    "            x = BatchNormalization()(x)\n",
    "            shortcut = BatchNormalization()(shortcut)\n",
    " \n",
    "            x = Add()([x, shortcut])\n",
    "            x = Activation('relu')(x)\n",
    "            \n",
    "            shortcut = x\n",
    " \n",
    "        else:\n",
    "            x = Conv2D(64, (1, 1), strides=(1, 1), padding='valid')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)\n",
    "            \n",
    "            x = Conv2D(64, (3, 3), strides=(1, 1), padding='same')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)\n",
    " \n",
    "            x = Conv2D(256, (1, 1), strides=(1, 1), padding='valid')(x)\n",
    "            x = BatchNormalization()(x)            \n",
    " \n",
    "            x = Add()([x, shortcut])   \n",
    "            x = Activation('relu')(x)  \n",
    " \n",
    "            shortcut = x        \n",
    "    \n",
    "    return x\n",
    " \n",
    " \n",
    " \n",
    "def conv3_layer(x):        \n",
    "    shortcut = x    \n",
    "    \n",
    "    for i in range(4):     \n",
    "        if(i == 0):            \n",
    "            x = Conv2D(128, (1, 1), strides=(2, 2), padding='valid')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)        \n",
    "            \n",
    "            x = Conv2D(128, (3, 3), strides=(1, 1), padding='same')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)  \n",
    " \n",
    "            x = Conv2D(512, (1, 1), strides=(1, 1), padding='valid')(x)\n",
    "            shortcut = Conv2D(512, (1, 1), strides=(2, 2), padding='valid')(shortcut)\n",
    "            x = BatchNormalization()(x)\n",
    "            shortcut = BatchNormalization()(shortcut)            \n",
    " \n",
    "            x = Add()([x, shortcut])    \n",
    "            x = Activation('relu')(x)    \n",
    " \n",
    "            shortcut = x              \n",
    "        \n",
    "        else:\n",
    "            x = Conv2D(128, (1, 1), strides=(1, 1), padding='valid')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)\n",
    "            \n",
    "            x = Conv2D(128, (3, 3), strides=(1, 1), padding='same')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)\n",
    " \n",
    "            x = Conv2D(512, (1, 1), strides=(1, 1), padding='valid')(x)\n",
    "            x = BatchNormalization()(x)            \n",
    " \n",
    "            x = Add()([x, shortcut])     \n",
    "            x = Activation('relu')(x)\n",
    " \n",
    "            shortcut = x      \n",
    "            \n",
    "    return x\n",
    " \n",
    " \n",
    " \n",
    "def conv4_layer(x):\n",
    "    shortcut = x        \n",
    "  \n",
    "    for i in range(6):     \n",
    "        if(i == 0):            \n",
    "            x = Conv2D(256, (1, 1), strides=(2, 2), padding='valid')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)        \n",
    "            \n",
    "            x = Conv2D(256, (3, 3), strides=(1, 1), padding='same')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)  \n",
    " \n",
    "            x = Conv2D(1024, (1, 1), strides=(1, 1), padding='valid')(x)\n",
    "            shortcut = Conv2D(1024, (1, 1), strides=(2, 2), padding='valid')(shortcut)\n",
    "            x = BatchNormalization()(x)\n",
    "            shortcut = BatchNormalization()(shortcut)\n",
    " \n",
    "            x = Add()([x, shortcut]) \n",
    "            x = Activation('relu')(x)\n",
    " \n",
    "            shortcut = x               \n",
    "        \n",
    "        else:\n",
    "            x = Conv2D(256, (1, 1), strides=(1, 1), padding='valid')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)\n",
    "            \n",
    "            x = Conv2D(256, (3, 3), strides=(1, 1), padding='same')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)\n",
    " \n",
    "            x = Conv2D(1024, (1, 1), strides=(1, 1), padding='valid')(x)\n",
    "            x = BatchNormalization()(x)            \n",
    " \n",
    "            x = Add()([x, shortcut])    \n",
    "            x = Activation('relu')(x)\n",
    " \n",
    "            shortcut = x      \n",
    " \n",
    "    return x\n",
    " \n",
    " \n",
    " \n",
    "def conv5_layer(x):\n",
    "    shortcut = x    \n",
    "  \n",
    "    for i in range(3):     \n",
    "        if(i == 0):            \n",
    "            x = Conv2D(512, (1, 1), strides=(2, 2), padding='valid')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)        \n",
    "            \n",
    "            x = Conv2D(512, (3, 3), strides=(1, 1), padding='same')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)  \n",
    " \n",
    "            x = Conv2D(2048, (1, 1), strides=(1, 1), padding='valid')(x)\n",
    "            shortcut = Conv2D(2048, (1, 1), strides=(2, 2), padding='valid')(shortcut)\n",
    "            x = BatchNormalization()(x)\n",
    "            shortcut = BatchNormalization()(shortcut)            \n",
    " \n",
    "            x = Add()([x, shortcut])  \n",
    "            x = Activation('relu')(x)      \n",
    " \n",
    "            shortcut = x               \n",
    "        \n",
    "        else:\n",
    "            x = Conv2D(512, (1, 1), strides=(1, 1), padding='valid')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)\n",
    "            \n",
    "            x = Conv2D(512, (3, 3), strides=(1, 1), padding='same')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)\n",
    " \n",
    "            x = Conv2D(2048, (1, 1), strides=(1, 1), padding='valid')(x)\n",
    "            x = BatchNormalization()(x)           \n",
    "            \n",
    "            x = Add()([x, shortcut]) \n",
    "            x = Activation('relu')(x)       \n",
    " \n",
    "            shortcut = x                  \n",
    " \n",
    "    return x\n",
    " \n",
    " \n",
    " \n",
    "x = conv1_layer(input_tensor)\n",
    "x = conv2_layer(x)\n",
    "x = conv3_layer(x)\n",
    "x = conv4_layer(x)\n",
    "x = conv5_layer(x)\n",
    " \n",
    "x = GlobalAveragePooling2D()(x)\n",
    "output_tensor = Dense(K, activation='softmax')(x)\n",
    " \n",
    "resnet50 = Model(input_tensor, output_tensor)\n",
    "resnet50.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "02_03.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
